[toc]

# 课后习题

## 网络体系结构的工作流指的是什么，数据流指的是什么？

* 工作流：由不同协议定义的数据流的处理方式或通信方式，包括网络交换、网络路由等
* 数据流：由源IP，目的IP，源端口，目的端口和协议相同的且在较短时间间隔内的一系列数据报文组成数据流

## 试分别列举OSI、TCP/IP和NDN的体系结构元素

**OSI**

* 物理层：位于最底层，为数据链路层实体提供建立、传输、释放所必须的物理连接，并且提供透明的比特流传输，同时定义了网络的机械特性、电气特性、功能特性和规程特性
* 链路层：数据单位是帧，将原始的传输线路变换成逻辑传输线路，实现二进制信息块的传输，为网络层提供可靠的数据信息，具有流量控制功能
* 网络层：控制子网的通信，功能有路由选择、网络连接、链路复用和拥塞控制等
* 传输层：实现可靠的端到端数据传输和数据分段，还提供拥塞控制功能
* 会话层：在不同机器上的用户之间建立会话
* 表示层：确定了通信的数据描述格式，在不同机器系统间进行转换和相互操作
* 应用层：向应用提供服务

**TCP/IP**

分为：应用层、传输层、网际互联层和网络访问层

应用层=应用层+表示层+会话层
网际互联层=网络层
网络访问层=数据链路层+物理层

**NDN**

比TCP/IP层多了安全层，内容块层和策略层

NDN的提出主要是想要替代IP网络的主体地位，解决当前IP网络存在的以下问题：不够安全、资源浪费、带宽竞争和拥塞等等

## 什么叫南北向流量，什么是南北向接口？

针对经典的三层网络架构（接入层、汇聚层、核心层）来讨论
* 接入层：负责服务器的接入和隔离
* 汇聚层：网络接入层和核心层的中间层，减轻核心层的负担
* 核心层：网络的高速交换主干

* 南北向流量：内网和外网间的流量叫做南北向流量
* 东西向流量：交换机内部、机房内部和AS等内部流量称为东西向流量
* 北向接口：厂家或运营商进行接入和管理网络的接口，即向上提供的服务
* 南向接口：提供对其他厂家网管系统或设备的接口，支持多种形式的接口协议，即向下提供服务

## 接入网与子网有什么区别？

* 接入网：由业务节点接口和相关用户网络接口之间的一系列传送实体所组成的为传送信息业务提供所需传送承载能力的实施系统，它向用户提供了包括有线、无线、固定或移动等多种通信接入手段
* 子网：为了确定网络区域，必须分开主机和路由器的每个接口，从而产生了若干个分离的网络岛，接口段连接了这些独立网络的端口，这些独立的网络岛即为子网
* 区别：接入网是骨干网高用户终端之间的所有设备，是网络网；而子网是对网络的逻辑划分

## 对于网关的介绍

网关实质上是一个网络通向其他网络的IP地址

比如有网络A和网络B，网络A的IP地址范围为“192.168.1.1~192. 168.1.254”，子网掩码为255.255.255.0；网络B的IP地址范围为“192.168.2.1~192.168.2.254”，子网掩码为255.255.255.0

在没有路由器的情况下，两个网络之间是不能进行TCP/IP通信的，即使是两个网络连接在同一台交换机（或集线器）上，TCP/IP协议也会根据子网掩码（255.255.255.0）判定两个网络中的主机处在不同的网络里

而要实现这两个网络之间的通信，则必须通过网关：如果网络A中的主机发现数据包的目的主机不在本地网络中，就把数据包转发给它自己的网关，再由网关转发给网络B的网关，网络B的网关再转发给网络B的某个主机

## 互联网的管理结构是怎样的？

网络管理定义：监测、控制和记录电信网络资源的性能和使用情况，以使网络有效运行，为用户提供一定质量水平的电信业务

从网络管理范畴来分类，可分为：对网“路”的管理，即针对交换机、路由器等主干网络进行管理；对接入设备的管理，即对内部PC、服务器、交换机等进行管理；对行为的管理，即针对用户的使用进行管理；对资产的管理，即统计IT软硬件的信息等

网络管理结构通常包括：被管设备、管理对象、管理信息库、管理信息结构和管理协议等

供给关系从管理者与被管理者、网络提供商和用户、管理协议和管理信息库来讨论

## 试举出网络体系结构实现模型的两个例子

例子一：是否需要拥塞控制

Internet这个网络是需要拥塞控制的，原因是Internet网关会丢弃约10%的数据包

据统计，Internet上95%的数据流使用的是TCP/IP协议，它的拥塞控制机制对通信鲁棒性具有特别重要的意义

例子二：在哪里实现拥塞控制功能

目前在Ipv4上实际使用的拥塞控制基本上是建立在TCP的窗口控制基础之上的，此时IP层的路由器所起的作用相对较小；不过目前IP层控制拥塞的研究逐渐增多，已经形成了一个新的研究热点

## 网络的演化指的是什么，为何称为演化？

网络的演化指：需求的演化、结构的演化、设备的演化和业务的演化

随着新应用的产生，原有的网络设施如硬件、协议等不能满足新的业务需求，需要对网络进行改进、优化，基于对现有网络存在的问题，提出新的解决思路，这就是一个演化的过程

## IP地址有哪些属性（即一个IP地址能够表达或体现出的语义）？

从内容、形式、使用、管理四个方面回答

内容上，有A、B、C、D四类；形式上，与位数无关（IPv4和IPv6位数不同，但属性类似），都有前缀和定位标识符（网络号和主机号）；使用上，IP地址与某个特定机器相对应；管理上，IP地址有对应的主机拥有者和主机地理位置

## 如果以下列IP地址为IP地址前缀的起始位置，则它们允许的最短掩码分别是多少？

1.2.0.0，192.128.0.0，10.0.3.0，202.112.32.0

15，9，24，19

## 为什么需要静态NAT？

NAT（Network Address Translation）指在网络边界实现私有地址与全局地址的转换和IP报头重写（P13）

静态NAT指将内部网络的私有IP地址转换为公有IP地址，是一对一的永久映射，某个私有IP地址只转换为某个公有IP地址；

当外部网络需要通过固定的全局可路由地址访问内部主机时，静态NAT就显得十分重要，如外部网络对内部网络中某些特定设备（如服务器）的访问

## IPv6地址中端口标识分配的三种方式分别适用于什么场合？

三种方式分别为从链路层地址导出、DHCPv6服务器分配和手工配置

在无状态地址自动配置方式下，将链路层地址的后64位作为端口标识（使用EUI-64转换算法得到）；在有状态地址自动配置方式下，使用动态主机配置协议（DHCPv6）分配端口标识；在手动配置情况下由管理员指定

## 假设有一些行业的信息化系统是纵向进行IPv4地址分配的，......

使用私有地址10/8。如果这些系统在某个城市的分系统需要进行横向互联，由于都是在10/8的范围内分配地址，因此可能会出现地址冲突，这时使用NAT444能否解决问题？

![1-1](1-1.png)

![1-2](1-2.png)

## 怎么使用NAT64实现IPv4用户访问IPv6服务器？

可通过手工配置静态映射关系，实现IPv4网络侧用户发起访问IPv6网络资源

## 关于MAP技术，请考虑下列问题：......

（1）为什么需要无状态翻译，什么情况下需要双重翻译？

无状态是指IPv4/IPv6地址和传输层端口之间的映射关系完全由算法决定，设备不需要维护映射状态表

互联网的基本特性就是“无连接”的体系结构，路由器不需要维护状态，IPv4/IPv6翻译器本身也是一个路由器，因此无状态的IPv4/IPv6翻译器对于运营商来讲更具有价值；同时，无状态IPv4/IPv6翻译（IVI）技术具有可扩展性、可管理性和安全性好的特点，并支持双向发起的通信，在需要复用公有IPv4地址以高效使用IPv4地址资源时需要双重翻译

（2）哪些节点需要MAP功能？

CE（Customer Edge）和BR（Border Router）

（3）怎么用MAP来实现DS-Lite所支持的访问场景（使用共享IPv4地址的用户接入IPv6主干网，并通过其访问另一个互联的IPv4网络中的节点）？

使用无状态双重IPv4/IPv6翻译模式，用户的IPv4终端设备，可通过CE一次翻译访问网内纯IPv6服务器的信息资源，同时可通过CE和BR双重翻译访问IPv4互联网上的信息资源，并与其他用户互访

## 路由器中的交换信息表FIB应包括哪些内容？如果要支持MPLS交换，FIB还要包括哪些内容？

![fib](fib.png)

若要支持MPLS，还需要交换表，内容包括In Tag,Address Prefix,Out Port,Out Tag

### MPLS

独立于第二和第三层协议，诸如ATM 和IP。它提供了一种方式，将IP地址映射为简单的具有固定长度的标签，用于不同的包转发和包交换技术。它是现有路由和交换协议的接口，如IP、ATM、帧中继、资源预留协议（RSVP）、开放最短路径优先（OSPF）等等。

在MPLS中，数据传输发生在标签交换路径（LSP）上。LSP 是每一个沿着从源端到终端的路径上的结点的标签序列。现今使用着一些标签分发协议，如标签分发协议（LDP）、RSVP 或者建于路由协议之上的一些协议，如边界网关协议（BGP）及OSPF。因为固定长度标签被插入每一个包或信元的开始处，并且可被硬件用来在两个链接间快速交换包，所以使数据的快速交换成为可能。

#### FEC（Forwarding Equivalent Class）

将具有相同转发处理方式的报文分为一类，称该类报文为一个转发等价类。其用来描述一系列分组用相似或同样的特征，其可能以同样的方式被运送，就是，它可能被束缚到相同的MPLS标签中。

从转发的行为来看，它们都具有相同的转发属性。一种FEC是一组单目广播分组，其目的地址均与一个IP地址前缀相匹配。另一种FEC是分组的源与目的地址都相同的一组分组。

FEC的划分方式非常灵活，可以是以源地址、目的地址、源端口、目的端口、协议类型或VPN等为划分依据的任意组合。

### LDP

标签分发协议LDP（Label Distribution Protocol）是 MPLS 体系中的一种主要协议。在 MPLS 网络中，两个标签交换路由器（LSR）必须用在它们之间或通过它们转发流量的标签上达成一致。

## 路由器的交换结构交换的是什么？需要考虑什么问题？

交换的是报文，需要考虑以下几个关键点：吞吐量，报文丢失率，报文延时，缓冲空间和实现的复杂性等

## 以太网三层交换机使用的是哪种三层交换模型，为什么？

以太网使用的是Overlay（叠加）模型，它在链路层使用MAC（介质访问控制）协议，网络层使用IP（网际协议）协议，符合叠加模型的具有层次型体系结构的特征

链路层方面：每个以太网主机都有一个唯一的以太网地址，从技术上讲，每个地址属于适配器，地址通常固化在ROM中，链路层有自己的传输算法，在以太网上传输的每一帧可由连到以太网的所有适配器接收到，每个适配器将这些帧的地址与自己的地址比较，尽享主机提交发送自己的帧；网络层方面：每个主机或路由器都有IP地址

可以看出，以太网侧重的是适配器（L2）的实现，综上所述，以太网三层交换机使用的是Overlay（叠加）模型

## IP over WDM使用的是哪种三层交换模型，为什么？

IP over WDM使用的是Peer（对等）模型

IP over WDM采用WDM网络承载IP业务，通过其波道复用技术，在WDM的广域网或城域网内，相邻的节点可以用WDM提供的点到点的光路通信，如果有些路由器间没有直通光路，则可以通过其他的路由器作多跳连接；它没有使用MAC协议，IP层和WDM层运行同一个路由协议，并且共享可到达性信息，使边缘设备可以看到核心网络的拓扑情况

IP OVER WDM技术具备一定的明显技术优势：超大系统传输带宽、超长的传输距离和完善的网络保护功能等，所以它有基于集成型体系结构的特征

综上，IP over WDM使用的是Peer（对等）模型

## IP三层交换的叠加模型和对等模型在设计理念上有什么不同？

两个模型的侧重点不同

叠加模型有以下优点：易于实现且广为人知；ISP不参与用户路由；用户网络与ISP网络很好地隔离等

缺点：需要全互联网络模型来实现最佳选路；必须手动定制不同的虚电路；实现时伴随着大量的封装

对等模型有以下优点：确保用户间的最佳路由；扩展性强；以整个用户站点为扩展基点，而不是以用户站点之间的链路

缺点：服务商参与用户路由；服务商负责用户路由的收敛；PE路由器携带所有客户的路由；服务商需要精通路由技术

可以看出，叠加模型侧重在很好的层次型体系结构这个特征，要求在用于报文交换是注重L2的交换能力；而对等模型则是更多的从用户的角度进行考虑，具有基于集成型体系结构的特征，同时注重于相邻节点平等地进行数据交换等

在设计时，需要考虑到具体的实际场景的需求，然后根据IP三层交换的具体的优缺点进行选择

## MPLS的标记为什么必须是上行分配？

路由获取就是由下层交换机向上层交换机进行分配的，而且考虑一种情况，2个上层交换机连接同一个下层交换机，若上层发起标签分配，那他们各自分配的标签如何保持一致？此时必须采用上行分配

## 对于P52的标记分配例子（标记栈），图中的路由器分别执行什么LDP（标记分发协议）规程进行标记分配？

分配规程的概念见PPT 61

* PE1，有条件PUSH，图中1）报文进入隧道，标签入栈，因为PE1是这条路有的LSP外向节点，所以为有条件push
* P，无条件PUSH，图中2）报文进入RSVP，标签入栈
* P，无条件PULL，图中3）报文离开RSVP，标签出栈

## IP报文交换模型中的三个平面分别对应什么时间粒度？

IP报文交换的三个平面应该指的数据平面（报文流）、控制平面（分布式算法）、管理平面（集中控制）；数据平面的时间粒度为ns，控制平面的时间粒度为ms，管理平面的时间粒度为天

## 网络资源分配机制评价的公平指数方法有什么缺陷，最大-最小比率方法有什么缺陷？

* 公平指数方法合理，但不一定均匀地分配资源
* 最大最小比率，只求了最大与最小的比例，当分布很集中时，只用个别的最大与最小求出的值不能代表这种资源的分配使用情况

![2-1](2-1.png)

## 试比较资源分配拍卖机制与eMule信用机制的异同

* 同：都用于在网络中给用户分配资源，调整用户行为的权重
* 异：拍卖机制是谁出的钱多就给谁资源多；eMule信用机制则是按照信用进行排序，信用高的优先资源的使用

##  RED中的Qavg是单调的吗？

$Q_{avg}\leftarrow Q_{avg}+W_q*qlen$

以前的平均队列长度加上权重乘以当前队列长度

不一定是单调增加的，主要取决于当前队列长度和以前的平均队列长度的比：如果当前的队列长度大于以前的平均队列长度，则新计算出的平均队列长度会大于以前的平均队列长度；如果现在的队列长度小于以前的平均队列长度，则新计算出的平均队列长度会小于以前的平均队列长度

## RED中，maxth与minth的差别为什么要大于一个RTT内队列长度的增长？

如果maxth与minth的差别小于一个RTT内队列长度的增长，则经过一个RTT时间后，新到达的分组直接从全部保留在队列中变为全部丢弃，完全没有了按某一概率p将新到达的分组丢弃的特性

## 请用自己的语言来描述TCP是如何控制发送动作和发送量的

**如何控制发送动作**

在发送完一段数据之后，如果没有接收到对方返回的ack则会重发刚刚的数据，只有在接收到相应的ack后才会继续往下发送数据

在此基础上，可以为每一个分组设置一个超时计时器，若超过了这段时间仍然没有收到对方的确认，则重传前面发过的分组；若在超时计时器到期之前收到对方的确认，就撤销已设置的超时计时器

另外为了提高效率，可以采用累积确认的方法，接收方不必对收到的分组逐个发送确认，而是在收到几个分组后，对按序到达的最后一个分组发送确认即可

**如何控制发送量**

参考慢开始、拥塞避免、快重传、快恢复的过程

## TCP在收到3个dupACK之后为什么要减少ssthresh的值？

如果是通过重复的应答发现的阻塞，则这个报文可能还在途中，信道上仍有应答报文返回，可以判断此时的网络可能发生阻塞，但阻塞现象并不严重，此时减少ssthresh的值，可以预防可能将会发生的拥塞

## 设想一下在分别什么场景下MPLS需要使用LDP和RSVP作为信令协议？

* Rsvp：资源预留协议，为主机申请的，是一个单向的协议
* Ldp：标签分发协议，利用LDP交换标签映射信息的两个标签交换路由器（LSR）作为LDP对等节点，并且它们之间有一个LDP标签分发协议会话，在单个会话中，每一个对等节点都能获得其它的标签映射，也就是说这个协议是双向的

## 设使用TCP传输10MB数据,且......

![2-2](2-2.png)

![2-3](2-3.jpg)

## 路由表中存放什么内容？

路由表RIB中存放整个路由过程会用到的所有网络信息，并从中计算出最优路由路径以供转发表FIB使用

例如：存储直连路由信息、手工配置的静态路由信息以及动态获取的路由信息，其中，动态路由信息又会区分为内部网关协议的相关信息和外部网关协议的相关信息，如RIP的L-S图、OSPF的链路状态数据库以及BGP的路由表

**路由表中的每项都由以下信息字段组成**

* 网络 ID:主路由的网络 ID 或网际网络地址。在 IP路由器上，有从目标 IP 地址决定 IP 网络 ID 的其他子网掩码字段。
* 转发地址:数据包转发的地址。转发地址是硬件地址或网际网络地址。对于主机或路由器直接连接的网络，转发地址字段可能是连接到网络的接口地址。
* 接口:当将数据包转发到网络 ID 时所使用的网络接口。这是一个端口号或其他类型的逻辑标识符。
* 跃点数:路由首选项的度量。通常，最小的跃点数是首选路由。如果多个路由存在于给定的目标网络，则使用最低跃点数的路由。某些路由选择算法只将到任意网络 ID 的单个路由存储在路由表中，即使存在多个路由。在此情况下，路由器使用跃点数来决定存储在路由表中的路由。

## 什么是路由选择中的Next Hop,它如何确定？

Next Hop就是某个分组根据路由路径到达某个中间路由器时，路径上的下一个路由器的接口地址（IP地址）

开始时，根据路由协议获取相关网络信息，使用路由算法计算出通信两点间的路由路径，并将路由选择信息存储在路由表中，这里面就有Next Hop信息；之后，根据网络信息对这个Next Hop不断更新以保持其在最新的路由路径上

## 不收敛的路由表可以用吗？

可以用，因为链路状态发生改变时，在路由表重新收敛之前只能继续使用之前的路由表

路由收敛指网络的拓扑结构发生变化后，路由表重新建立到发送再到学习直至稳定，并通告网络中所有相关路由器都得知该变化的过程，也就是网络拓扑变化引起的通过重新计算路由而发现替代路由的行为

## 慢收敛现象是分布式系统的哪种问题？

慢收敛现象类似于分布式系统的循环等待问题：慢收敛就是RIP依靠定时器更新路由器的路由表，但当网络拓扑结构发生变化时，它收敛于新拓扑的速度慢，就有可能导致路由环的产生，使错误的数据重复发送

## OSPF是怎样通过链路状态来传递网络拓扑结构信息的？

紧邻的路由器会先比对两者的数据库描述信息，若出现不同，则会从对方那里获取新的数据库链路状态来更新自己的数据库，这个是通过链路状态请求与更新分组来完成的；若某条链路变化了，则与链路相对应的路由器将发布新的链路状态宣告，链路状态宣告有五种，都要被封装在链路状态更新分组中来进行传递

## 为什么说OSPF比RIP收敛快？

* RIP需要周期性的广播整个路由表，该广播周期为30秒。在一个较为大型的网络中，RIP协议会产生很大的广播信息，占用较多的网络带宽资源，大大降低了收敛速度
* 并且由于RIP协议30秒的广播周期，影响了RIP路由协议的收敛，甚至出现不收敛的现象。而OSPF是一种链路状态的路由协议，当网络比较稳定时，网络中的路由信息是比较少的，并且其广播也不是周期性的，因此OSPF路由协议即使是在大型网络中也能够较快地收敛。
* 若路径发生变化，RIP需要像波动一样逐渐从邻居传播到整个RIP网络，此过程非常缓慢；OSPF则使用层次化的路由体系，只需要在域内广播更新
* 一个条目变化时RIP需要广播包含所有条目的分组，而相比来说，OSPF只需要通告发送变化的链路状态的更新分组
* OSPF：路由器将其链路状态信息泛洪到路由区域内的其他所有链路状态路由器，它一旦收到来自邻居的LSP，不经过中间计算，立即将这个LSP从除接收该LSP的接口以外的所有接口发出，此过程在整个路由区域内的所有路由器上形成LSP的泛洪效应；RIP则不同，它必须首先运行Bellman-Ford算法来处理路由更新，然后才将它们发送给其他路由器，而链路状态路由协议则在泛洪完成后再计算SPF算法，因此OSPF达到收敛状态的速度比RIP快得多

## 路由算法和路由协议有什么区别？

路由算法是在给定一组路由器及连接路由器链路的情况下，找出一条从源节点到目标节点的最佳路径，通俗的讲，就是把路由器选择最佳路径的策略成为路由算法，是路由器的关键功能所在

路由协议是一系列的方法、规则，这些方法规则被路由器用来决定转发数据时所用的最优路径，也就是在路由指导IP数据包发送过程中事先约定好的规定和标准

* 关注点不同：路由算法关注的是计算出路由路径，而路由协议用于信息交换，关注的是整个路由过程各节点要遵守的规则，包括节点交互报文的格式、含义以及顺序等
* 层次不同：路由协议为路由算法提供支撑，路由算法需路由协议提供

## IP报文在转发时是怎样使用路由表和转发表的？

路由器的结构结构可划分为两大部分：路由选择部分和分组转发部分

路由选择部分也叫做控制部分，它的核心构件是路由选择处理机，它的任务是根据所选定的路由协议构造出路由表，同时经常或定期地和相邻的路由器交换路由信息而不断地更新和维护路由表，并在IP报文转发时提供基于路由选择算法的最优路由

而分组转发部分由三部分组成：交换结构、输入端口和输出端口，交换结构的作用就是根据转发表对分组进行处理，将某个输入端口进入的分组从一个合适的输入端口转发出去

* 转发指的是路由器根据转发表把收到的IP数据报从路由器合适的端口转发出去，它仅仅涉及到一个路由器
* 路由选择则涉及到很多路由器，路由表是许多路由器协同工作的结果，这些路由器按照复杂的路由算法，得出整个网络的拓扑变化情况，因而能够动态改变所选择的路由，并由此构造出完整的路由表

* 路由表一般仅包含从目的网络到下一跳的映射，用户可读性强
* 转发表则是从路由表得出的，它的每一行必须包含从要到达的目的网络到输出端口和某些MAC地址信息（如下一跳的以太网地址）的映射，可以用某些特殊硬件来实现

将转发表和路由表用不同的数据结构实现会实现会带来一些好处，这是因为在转发分组时，转发表的结构应当是查找过程最优化，但路由表则需要对网络拓扑变化的计算最优化。

## AS的内部路由与AS之间的外部路由有什么区别？

* AS的内部路由是可操作的路由信息，AS之间的外部路由是可达性的路由信息
* AS的内部路由使用内部路由协议，AS之间的外部路由使用外部路由协议
* AS内部一般具有统一的技术管理，可以指定统一的路径度量，因此AS内部的路由主要根据这种路径度量来进行，设法使得数据包在AS内尽可能有效地从源端传输到宿端口；而对AS之间的外部路由而言，由于各AS都运行自己选定的内部路由选择协议，并使用自己指明的路径变量（跳数、延时等），导致在各种内部路由协议之间建立一种共同的路径度量十分困难，因此AS之间的外部路由通常只考虑使得与自己AS网关直接相连的网络的路径最短即可

## 阅读BGP-4协议规范（RFC1771）的第九章（UPDATE Message Handing）......

* BGP路由更新的决策过程是怎样的？
* BGP路由的更新过程是怎样的？
* 将上述两个过程分别用流程图表示出来

![bgp-1](bgp-1.png)

![bgp-2](bgp-2.png)

## AS之间的Customer-Provider，Sibling-Sibling，Backup Sibling和Indirect Provider等关系如何通过路由通告来实现？

* Custuomer-Provider: Provider AS答应通告Customer AS的路由，使得Customer AS可以被外界所访问，Customer AS则使用Providr AS提供的Internet路由或将Provider AS作为其默认路由，可以访问Internet
* Sibling-Sibling：Sibling AS之间互相通告对方的路由
* Backup Sibling：当一个Sibling AS（设为AS1）的外部路由不可用时，其Backup Sibing AS（设为AS2）作为其备份与其Sibling AS（设为AS3）互相通告对方的路由
* Indirect Provider：两个AS都与共同的第三方AS互相通告路由，第三方的AS起传递作用

## 一个校园网如果存在多个接入不同的出口，应该怎样规划路由？

![nat](nat.png)

## 试分别给出网络A到网络B、C、D、E、F的最短通路向量......

![3-1](3-1.jpg)

![3-2](3-2.jpg)

* **A-AS1-AS4-AS5-D**
* **A-AS1-AS4-AS5-AS7-F**
* provider和customer可以反过来路由，满足最短即可

## 为什么要区分CE和PE？

* CE(Customer Edge)：用户边缘设备，是发起或终结业务的一侧，有接口直接与服务器商相连，CE感知不到VPN的存在。有接口直接与服务提供商相连，可以是路由器，也可以是交换机等。
* PE(Provider Edge)：提供商边缘设备，一般为服务提供商骨干网络的边缘路由器，为CE提供PWE3业务。在MPLS网络中，对VPN的所有处理都发生在PE上。 CE和PE的划分主要都是从运营商和用户的管理范围来划分的。这两者是范围的边界。

区分CE和PE的原因如下：

* 管理范围：CE为客户提供到PE路由器的连接用户站点内部可以自主管理；PE负责与其它PE路由器交换信息，主要由运营商负责管理
* 控制权：CE用来控制VPN内部业务而不考虑具体通信的实现，用户仍然只需要按自己需求配置本地设备，不用感知广域网传输过程的任何改变；ISP通过PE对自己的骨干网络进行独立控制，而不需要考虑VPN内部的业务

## VPN使用的IP地址有什么特点，与NAT有什么区别？

特点：VPN有独立的内部通信私有地址，不同的VPN可以使用相同的私有地址空间，每一个内部专用网至少有一个路由器具有合法的全球IP地址

区别：
* 在与外部网络通信时，NAT路由器将专用网内部的主机发往因特网上主机的数据报的源IP地址转换成NAT路由器的全球IP地址，对目的地址不做修改；而VPN路由器不更改数据报的源地址和目的地址，而是将数据包加密在添加新的源地址和目的地址，新添的地址分别是两个VPN路由器的全球IP地址
* 通过NAT实现的连接是单向的，使用私有IP地址的主机可以通过NAT访问外部网络中的主机，但外部网络中的主机无法访问单位内部使用私有IP地址的主机，而通过VPN，外部主机可以访问到单位内部使用私有IP地址的主机，并且通过公用网络连接的两个局域网之间也可以进行安全通信

## 按照PW Reference Diagram， Native的以太帧在哪里变成PW的以太帧？

在NSP(Native Service Processing)完成对Native的以太帧的封装，形成PW的以太帧，通过PW传输给对端PE

## BGP Auto-Discovery要自动发现什么，它是如何做到的？

自动检测VPLS域中PE的变化情况，主要是实现PE邻居的自动发现

自动发现协议通过在PE邻居间传递自动发现信息实现PE邻居的自动发现机制，假设有两个VSI站点属于同一个VPLS域，设为PE1和PE2：

* VPLS成员发现是建立PW的第一阶段
* 使用BGP协议来实现BGP-AD类型的本地VSI信息的扩散，使BGP-AD地址族内的VSI成员间相互交换信息，达到成员发现的目的
* 当PE1完成配置完VPLS-ID、RD、RT、VSI-ID等配置后，将这些信息封装到BGP的Update消息中，作为BGP-AD报文，由BGP向所有BGP域内的对端PE发送，进行PW协商

## EoMPLS中信令协议的作用是什么？......

### LDP是如何实现信令功能的
### BGP是如何实现信令功能的

标签分发协议LDP（Label Distribution Protocol）是 MPLS 体系中的一种主要协议。在 MPLS 网络中，两个标签交换路由器（LSR）必须用在它们之间或通过它们转发流量的标签上达成一致。

信令协议的作用是在同一VPLS的PE之间建立、维护和拆除PW

* LDP：LDP按照分布方式控制标签交换路径的建立，每个节点根据各自路由模块得到的路由信息为FEC分配标签，并公布给与其相邻的上下游节点 从而在每个节点生成标签信息库LIB；这样带有标签的分组到达LSR之后，即可根据分组携带的标签和LIB中的信息采用交换的方式完成此分组的转发，当路由信息发生改变时，需要重新协商FEC之间的绑定关系并更新LIB，LDP将网络层的路由信息直接映射到建立在数据链路层的LSP上从而建立起网络层的LSP
* BGP：使用BGP标签协议传递标签信息建立PW，本端PE把本端的标签块和邻居收来的标签块通知给远端PE，通过一系列的计算得到PW标签进而建立PW从而建立MPLS L2VPN服务。

## 按Multi-AS VPLS的第一种方案， PE1的以太帧传输到PE2需要经过怎样的封装？

![4](4.jpg)

# 补充知识

## IP分类

A、B、C、D、E

Categoty|Range|Private Range
---|---|---
A|0.0.0.0-127.255.255.255|10.0.0.0-10.255.255.255
B|128.0.0.0-191.255.255.255.255|172.16.0.0-172.31.255.255
C|192.0.0.0-223.255.255.255|192.168.0.0-192.168.255.255

D类地址作为组播地址来使用，范围：224.0.0.0-239.255.255.255
E类地址则保留研究使用（至今未使用，浪费了）
其中ABC类地址中有一部分地址用作特殊用途，故不会作为公网IP来分配

### IP地址分配

C类200.1.1/24 分给四个子网：A18，B70，C20，D50，给出方案

**机器数必须是二的幂次**

地址|子网|机器数
---|---|---
200.1.1.0/25|B|128
200.1.1.128/26|D|64
200.1.1.192/27|C|32
200.1.1.224/27|A|32

**子网掩码看有几位不变即可**

## CIDR

最早期按照ABCDE类来划分地址，会导致地址使用的浪费。而使用CIDR后，将原有地址分类的界限打破，使得其网络前缀可以有更多种形式来表达网络前缀。

作用：实现子网划分与地址聚类，压缩路由表规模，提高IP地址的使用效率；可以将某类地址细分或者聚合。

形式：xx.xx.xx.xx/xx

## IP地址管理

微观管理：
* 用户：获取地址，让网络知道该用户的地址是什么
  * 静态配置：可供DNS使用
  * 动态配置：DHCP
  * 地址解决：ARP
* 网络服务提供商：地址规划（路由、流控、安全）

宏观管理：
国际组织管理IP地址的分配，以及使用权和所有权。

## IPV4问题

* 地址不够使用
* 报头拓展能力差
* 主机地址配置的手工管理导致容易出错
* 配置的长效性增加了重新编址的难度

## IPV6

![ipv6](ipv6.png)

**IPv6的扩展报头的含义**
* Hop-by-hop options：这个报头定义沿途的路由器必须检查的信息，目前只定义了一个选项：要求支持超 过64K的数据报文，称为jumbogram；这个报头要求 沿途的路由器进一步检查报文的净负荷区，以发现其中的传输控制信息。
* Routing：这个报头用于source routing功能，它列举出了通往宿主机的路径上必须经过的路由器，可以是全部路由器（strict routing），也可是部分路由器（loose routing）。
* Fragmentation：允许源主机对超长报文进行分段，并对分段的报文进行标识（分段和合段只在源点和宿点进行）。
* Authentication：用于报文鉴别，包含三部分：
  * 头四个字节保存next header数；
  * 然后是32比特的密钥编号（具体使用的密钥体制和密钥分配方法由用户确定）；
  * 最后是MD5的校验和(128比特)。
* Encrypted security payload：用于传送加密的报文，起始的32比特为密钥编号，随后是加密的报文内容。缺省的加密算法是DES－CBC，这时加密报文的起始为初始向量IV。
* Destination options:这里包含的信息是给宿主机解释和使用的。

### IPv6的编址

* 单播：单播地址标识的是此类型地址范围内的单个接口；只要单播路由拓扑无误，去往某个单播地址的数据包就可以发送到单一的接口。
* 组播：组播地址标识的是相同或者不同主机上的零到多个接口。只要组播路由拓扑无误，发往某个组播地址的数据包就可以被发送到地址所标识的所有接口。
* 任播：任播地址标识的是多个接口。只要任播路由拓扑无误，去往某个任播地址的数据包就可以被发送到所有配置为该地址的接口中距离源最近的那个接口。

**单播地址说明**

* aggregate global unicast address可聚合全球单播地址，由IANA分配的可在全球路由的公网IP地址
* link-local address本地链路地址
  * 原因：因为一个界都可以配置多个IPv6地址，所以学习路由很可能出现很多下一跳。所以出现 link-local address唯一标识一个节点。
  * 功能：两个IPv6设备之间的通信（类比ARP）；计算路由协议中的下一跳计算。
  * 使用：当在一个节点启用IPv6，启动时节点的每个接口自动生成一个link-local address，其前缀64位为标准指定的，其后64位按EUI-64格式来构造
  * 使用范围：只能在本地链路使用，不能在子网间路由
* site-local address本地站点地址（已被RFC3879取消，并入link-local）
* IPv6的私网地址，就像IPv4中的私网保留地址一样，只能在本站点内使用，不能在公网上使用

**组播地址说明**

![ipv6-2](ipv6-2.png)

* 0xFF：最高8比特为 11111111，标识此地址为IPv6组播地址。
* Flags：4比特
  * 0位：保留位，必须取0
  * R位：取 0表示非内嵌 RP的 IPv6 组播地址 ;  取 1表示内嵌 RP的 IPv6 组播地址（此时 P、T位也必须置 1）
  * P位：取 0表示非基于单播前缀的 IPv6 组播地址; 取 1表示基于单播前缀的 IPv6 组播地址（此时 T位也必须置 1）
  * T位：取 0表示由 IANA 永久分配的 IPv6 组播地址 ;取 1表示非永久分配的 IPv6 组播地址
* Scope：4比特。用来标识该 IPv6组播组的应用范围
* Group ID：112 比特，IPv6组播组标识号。用来在由 Scope字段所指定的范围内唯一标识 IPv6 组播组，该标识可能是永久分配的或临时的，这由 Flags字段的 T位决定。

**scope取值**

![scope](scope.png)

**预留的IPv6组播地址**

![预留地址](预留地址.png)

**基于单播前缀**

![单播前缀](单播前缀.png)

* Flags：R位置 0，P、T位则分别置 1，表示基于单播前缀的组播地址。
* Scope：如 2.1.1  图 1表 2所示。
* Reserved：8比特。保留字段，必须为 0。
* Plen：8比特。表示网络前缀的有效长度（单位为比特）。
* Network prefix：64比特。表示该组播地址所属子网的单播前缀，有效长度由 Plen字段指定。
* Group ID：32比特。表示 IPv6组播组标识号。

#### 内嵌RP地址

![内嵌](内嵌.png)

* Flags：R、P和 T位均置 1，表示内嵌 RP地址的组播地址。
* Scope：如 2.1.1  图 1表 2所示。
* Reserved：4比特。保留字段，必须为 0。
* RIID：4比特。表示 RP地址的接口 ID。
* Plen：8比特。表示 RP地址前缀的有效长度（单位为比特）。
* Network prefix：64比特。表示 RP地址前缀，有效长度由 Plen字段指定。
* Group ID：32比特。表示 IPv6组播组标识号。

**应用举例**

假设网络管理员想在 2001:DB8:BEEF:FEED::/64 网段中设置 RP，则内嵌 RP地址的 IPv6 组播地 址为 FF7X:Y40:2001:DB8:BEEF:FEED::/96，可分配 32比特的 Group ID，内嵌于其中的 RP地址 为 2001:DB8:BEEF:FEED::Y/64。

如果网络管理员想在IPv6组播地址中保留更多可分配的Group ID，可以选择更短的RP地址前缀：譬如取 Plen = 0x20 = 32 bits，则此时内嵌 RP地址的 IPv6组播地址为 FF7X:Y20:2001:DB8::/64， 可分配 64比特的 Group ID，内嵌于其中的 RP地址为 2001:DB8::Y/32。

说明：X表示任意合法的 Scope，Y代表 1～F的任意一个十六进制数。

### EUI-64

通俗的来说，假如网络状况出现了问题，没办法获取DHCPv6服务来获得一个IPv6地址，那么这个时候可以以端口的MAC地址加上一些规则来生成一个IPv6地址。

* 格式：扩展唯一标识符
  * 在IPv6中，无状态自动配置机制使用EUI-64格式来自动配置IPv6地址；
  * 所谓无状态自动配置是指：在网络中没有DHCP服务器的情况下，允许节点自行配置IPv6地址的机制。
* 构造规则：根据端口的MAC地址再加上固定的前缀来生成一个IPv6地址。
* 原理：自动将48bit的以太网MAC地址拓展成64bit，再挂在一个64bit的前缀后面，组成IPv6地址。

### ICMPv6

* IPv6版本的ICMP协议（即IPv6的控制协议）
  * IPv6协议的基本组成部分，每个IPv6节点都必须支持
  * 标识ICMPv4的Protocol值为 1，标识ICMPv6的Next Header值为58
* ICMPv6提供报告数据包的错误信息、执行网络层诊断等功能

### Neighbor Discovery （邻居发现，ND）

* 相当于IPv4的ARP，ND的报文由ICMPv6承载；
* 路由器发现：主机找到可用的路由器(及其有效期)；
* 前缀发现：主机发现链路上存在的所有子网(及其有效期)，从 而知道哪些节点直接可达，哪些需要通过路由器可达；
* 实现地址自动配置；
* 地址解决：通过IP地址发现对应的链路地址；
* 下一跳确定：将报文的IP宿地址映射到下一跳的IP地址；
* 邻居不可达检测：发现邻居不再可达，这时可能需要重新进 行地址解决；
* 重复地址检测DAD：检查自己想用的地址是否已被别人使用；
* 重定向：路由器告诉主机特定宿点的更好的下一跳地址。

**NDP的协议报文类型**

* 路由器请求(Router Solicitation): 当端口使能，主机可发送 此报文，要求路由器立即返回路由器通告信息。
* 路由器通告(Router Advertisement): 路由器向其它节点通告 自己的存在，并给出有关的链路和网络参数；定期发布或 按请求发布。
* 邻居请求(Neighbor Solicitation): 用于确定邻接点的链路地 址，或根据现有的链路地址确定邻接点仍然可达，或用于 重复地址检测。
* 邻居通告(Neighbor Advertisement): 或者是对邻居请求的响 应，或者用于主动通告自己的链路地址变化。
* 重定向(Redirect): 路由器用于通知主机改变某个宿地址的下 一跳地址。通常存在多个出口路由器

## IPv4向IPv6过渡

**为什么需要IPv4和IPv6共存？**

如今，IP网络仍然是IPv4占主导地位，IPv6网络只是在小范围内部署和商用，从IPv4过渡到IPv6需要一个循序渐进的过程，不可能一气呵成。因此，在此期间内IPv4和IPv6必然会出现共存的场景。然而，IPv4和IPv6之间并不能相互兼容，且目前仍然存在大量的IPv4设备和用户，因此在网络演进的过程中势必要解决IPv4和IPv6兼容问题，这给互联网服务提供商（ISP）和用户带来了新的挑战。

**如何实现IPv4和IPv6共存？**

目前来说，实现IPv4和IPv6共存的策略和过渡技术有三种。第一种，使用双栈让您的主机或网络设备可以同时支持IPv4和IPv6双协议栈；第二种，通过隧道技术将IPv6数据包封装在IPv4数据包中；第三种，通过网络地址转换（NAT）技术将IPv6数据包转换为IPv4数据包，反之亦然。由于网络地址转换（NAT）技术主要针对互联网服务供应商，这里就不做多介绍，下面主要介绍双栈和隧道技术。

### 通过双栈实现IPv4和IPv6共存

双栈是实现IPv4和IPv6共存最基础、最直接的策略。使用该解决方案，可为ISP网络中的每个联网设备（包含使用IPv4和IPv6交换机）配置可同时运行IPv4和IPv6的功能。通常，双协议栈主机在和IPv4主机通信时会使用IPv4协议栈，而与IPv6主机通信时则会使用IPv6协议栈，其中双协议栈主机是通过使用域名系统（DNS）来查询目的主机采用的是哪一种协议栈。但通常在双协议栈主机或设备上，上层应用会优先选择IPv6协议栈，而不是IPv4协议栈。由于双栈可允许主机或网络设备同时访问现有的IPv4和IPv6，因此它是一种非常灵活的共存策略。但请记住，只有当接口同时需要IPv4和IPv6时，才能对所有主机或网络设备进行双栈。

![doublestack](doublestack.png)

**双栈的优缺点**

双栈是一种相对经济高效且配置简单的IPv6过滤技术，可有效避免两个协议栈之间转换（尽管该转换是一种有效的机制，但它的操作较复杂且性能较低）的环节，从而实现高效率且没有信息丢失的互通效果。此外，一旦实现IPv6通信，就会中断IPv4，未来IP网络更容易过滤到IPv6。

但是，双栈也不是长期的解决方案，因为它同时需要IPv4和IPv6，仍然会占用IPv4地址资源，本质上没有解决IPv4地址资源匮乏问题。与此同时，由于同时需要IPv4和IPv6，双栈对站点和设备的要求较高，因此，可能会涉及到服务器和网络设备升级，但网络的升级或重建是一项艰巨且繁琐的任务，需要花费较大的成本和较长的时间。

### 通过隧道技术实现IPv4和IPv6共存

隧道技术也是实现IPv4和IPv6共存时经常使用的典型解决方案。隧道技术通常将一种类型的协议流量封装在另一个协议数据包中进行传输。目前能够实现IPv4和IPv6共存的隧道技术有6to4、ISATAP、6PE、6VPE、Teredo、MPLS等，其中MPLS由服务提供商在其IPv4网络中部署，以便提高转发速率。与传统的IP路由方式相比，MPLS在转发数据时仅在网络边缘分析IP报文头，而不用在每一跳都分析IP报文头，从而节省了处理时间。MPLS隧道技术一般通过IPv4网络中的标签交换路径（LSP）连接到IPv6网络。与其他隧道技术相比，可提供更好的性能和优化路由。此外，6PE over MPLS是一种利用现有MPLS网络来实现IPv4到IPv6过渡的方法，该方案允许在仅使用IPv4的MPLS核心网络上运行IPv6，只需将PE路由器升级为支持双栈功能的6PE路由器即可。

![tunnel](tunnel.png)

**MPLS隧道技术的优缺点**

上述提及的6PE over MPLS是一种便捷的隧道方法，其主要的优势是对MPLS核心设备没有影响，可充分利用现有的核心网络，无需进行升级或重建，且配置也不会改变，可有效减少管理成本。与此同时，可将6PE设备连接到CE设备（客户边缘设备）的接口上，并为其配置转发IPv6流量，IPv4流量或IPv4和IPv6流量（具体取决于客户需求），而此时核心网络中的PE设备并不知道它们正在交换IPv6数据包。 由于MPLS隧道技术需要封装和解封装，所以其转发速率会有所降低，与此同时，在隧道的入口处会出现负载协议数据包的拆分，在隧道出口处会出现负载协议数据包的重组，从而增加了隧道出入口的复杂度，不利于大规模应用。更重要的是它也会遇到与上述双栈技术一样的问题——IPv4地址资源匮乏。

### NAT-PT

NAT-PT(Network Address Translator - Protocol Translator)附带协议转换器的网络地址转换器。是一种纯IPv6节点和IPv4节点间的互通方式，所有包括地址、协议在内的转换工作都由网络设备来完成。

支持NAT-PT的网关路由器应具有IPv4地址池，在从IPv6向IPv4域中转发包时使用，地址池中的地址是用来转换IPv6报文中的源地址的。此外，网关路由器需要DNS-ALG和FTP-ALG这两种常用的应用层网关的支持，在IPv6节点访问IPv4节点时发挥作用。如果没有DNS-ALG的支持，只能实现由IPv6节点发起的与IPv4节点之间的通信，反之则不行。如果没有FTP-ALG的支持，IPv4网络中的主机将不能用FTP软件从IPv6网络中的服务器上下载文件或者上传文件，反之亦然。

**优缺点**

采用NAT-PT方式进行过渡的优点是不需要进行IPv4，IPv6节点的升级改造，缺点是IPv4节点访问IPv6节点的实现方法比较复杂，网络设备进行协议转换、地址转换的处理开销较大，一般在其他互通方式无法使用的情况下使用。

**类型**

* 静态NAT-PT：静态模式提供了一对一的IPv6地址和IPv4地址的映射。IPv6单协议网络内的节点要访问的IPv4单协议网络内的每一个IPv4地址都必须在NAT-PT设备中设置。每一个目的IPv4地址在NAT-PT设备中被映射为一个具有预定义NAT-PT前缀的IPv6地址。这种模式中，每一个IPv6到IPv4映射需要一个源IPv4地址。静态NAT-PT模式跟IPv4中的静态NAT类似。
* 动态NAT-PT：动态模式也提供了一对一的映射，但是使用一个IPv4地址池。池中的源IPv4地址数量决定了并发的IPv6到IPv4转换的最大数目。在IPv6网络中IPv6单协议网络节点动态地把预定义的NAT-PT前缀增加到目的IPv4地址。这种模式需要一个IPv4地址池来执行动态的地址转换，动态NAT-PT模式和IPv4中的动态NAT类似。
* NAPT-PT：网络地址端口转换--协议转换模式提供多个有NAT-PT前缀的IPv6地址和一个源IPv4地址间的多对一动态映射。这种转换同时在第三层（IPv4/IPv6）和上层（TCP/UDP）进行。NAPT-PT和IPv4中的PAT转换类似。

**IPv4和IPv6并存的场景**

* 网络节点之间既可以用IPv4也可以用IPv6相互访问
* IPv4互联网(中的一个节点)访问IPv6互联网(中的一个节点)
* IPv6互联网访问IPv4互联网
* IPv4互联网穿越IPv6互联网访问IPv4互联网
* IPv6互联网穿越IPv4互联网访问IPv6互联网

**IPv4向IPv6过渡的基本方法**

* 双栈方法（IP地址获取方式：无状态、有状态）
  * 节点同时使用IPv4协议和IPv6协议，根据DNS的解析结果或收到的IP报文进行选择
* Translation
  * 单次翻译：实现IPv6与IPv4之间的地址格式映射和协议功能映射
  * 双重翻译：实现IPv4协议穿越IPv6互联网，或IPv6协议穿越IPv4互联网
* Tunneling：解决不同协议网络之间的穿越 (互联)
  * 配置隧道：隧道端点地址需要配置
  * 自动隧道：隧道端点地址从报文中导出，实际实现可用双重翻译代替

## NAT

在网络边界将私有ipv4地址转换为公有ipv4地址，并重写报头信息。

NAT类型|特点
---|---
静态NAT|一个私有IP固定映射到一个公有IP地址，提供内网服务器的对外访问服务
动态NAT|私有IP地址映射池中的公有IP，映射关系是动态临时的
NAPT|私有IP地址和端口号与同一个公有地址加端口进行映射

**静态映射**
静态映射对外隐藏了内部主机的真实IP地址，起到保护内部主机的作用。静态NAT还可以让外部主机通过内部全局地址访问内部的服务器，在内网需要向外提供网络服务而又不愿意暴露真实IP地址通常使用该类NAT技术。

**动态映射**
通过共享NAT地址池的IP地址动态建立NAT的映射关系。当内网主机需要进行NAT地址转换时，路由器会在NAT地址池中选择空闲的全局地址进行映射，每条映射记录是动态建立的，在连接终止时也被收回。

**复用PAT**
为了避免处理（转发）返回数据包时出现模糊（不知道送到哪里），必须修改额外的信息（比如外出通信的TCP/UDP端口号）和维护一张转换表，这样返回数据包就可以正确寻址到最初发起会话的源主机。

**NAT64讲解**

假如你的网络只有IPV6可以访问公网，而你想访问学校官网，可是学校官网只支持IPV4。这时候可以用NAT64做中间路由，你通过DNS查询的方式向NAT64发送学校官网的域名查询请求。NAT64收到这个查询请求后，查询学校官网的域名信息，发现学校官网只有IPV4的记录，并没有IPV6的记录。而这个时候，因为IPV6长度128位，IPV4才32位，完全可以将IPV4的地址嵌入到IPV6的地址中。于是，NAT64服务器就把学校官网的IPV4地址嵌入一个属于NAT64的IPV6地址中，并把这个IPV6地址作为你查询DNS的结果返回给你。这样，你在访问学校官网的时候，其实并不是访问学校官网的真实IP地址，而是发送请求到这个嵌套了真实地址的IPV6地址，而这个IPV6地址的目的地是NAT64服务器，NAT64服务器接到你的请求后，会根据IPV6中嵌入的IPV4地址替你把请求发给学校官网，学校官网接到请求后会把响应发回给NAT64服务器，然后NAT64服务器再把这个响应数据发回给你（其实NAT64在这个过程完全可以类比为“中间人”）。

如此一来，虽然你没有访问IPV4公网的权限，但是依然可以访问IPV4的网址。

**NAT444讲解**

采用了两级NAT，在客户端网络中使用第一级NAT，来实现私网地址到私网地址的映射；在运营商LSN中使用第二级NAT，实现私网地址到公网地址的映射。

举个简单例子，家用电信宽带，那么在家访问学校官网的时候，首先把请求发给电信服务器，这个过程用的就是第一级NAT，即用户私有地址到运营商私有地址；然后电信再把请求转发到学校官网，这个过程用的是第二级NAT，即运营商私有地址到公网地址。

**NAT和NAPT的区别**

* NAT：网络地址转换
* NAPT：网络地址端口转换

它们都是地址转换，NAPT与NAT的区别在于：NAT是一对一转换，NAPT是多对一转换。

通俗来说NAT是一个内部地址转换成一个外部地址进行通信的，而NAPT是多个内部地址使用同一地址不同端口转换成外部地址进行通信的。

简单来说：NAPT发送数据的时候会在源地址和目标地址上加上端口号（比如源地址：192.168.1.2:1010，目标地址：200.1.1.2:1020），回来的数据也是一样。

NAPT与NAT的区别在于，NAPT不仅转换IP包中的IP地址，还对IP包中TCP和UDP的Port进行转换。这使得多台私有网主机利用1个NAT公共IP就可以同时和公共网进行通信。（NAPT多了对TCP和UDP的端口号的转换）

## 网络交换概念和交换模型

**网络交换的概念**

网络设备的数据平面（处理报文流），控制平面（分布式算法），管理平面（集中控制）。
报文处理：路由查找、报文分类、执行动作、报文交换调度、到达输出端口

**第三层交换模型**

* IP流：网络中符合流规范和超时约束的IP报文集合。
* 第三层交换：将报文进行流分类处理，并在IP报文的转发处理中引入面向连接的处理机制。
* Overlay（叠加）模型：具有层次型体系结构的特征，网络层和链路层有各自路由协议互相独立。
* Peer（对等）模型：基于集成型体系结构的特征、相邻节点平等交换数据、只使用网络层标识和路由协议、使用数据流概念，由边界路由器决定数据如何穿越。
* IP over SDH（即将以太帧信号封装在SDH链路中进行传输）
  * 将IP报文直接映射到SDH帧的负荷区、链路层使用PPP协议实现SDH通路的数据传输、实现OC48以及更高速率上的IP传输。
* IP over WDM（指直接在光网上运行的因特网）
  * 将IP报文直接映射到SDH帧的负荷区、链路层使用PPP协议实现SDH通路的数据传输、实现OC48以及更高速率上的IP传输。

## MPLS

**基本概念**

基于标记交换和数据流的原理，采用peer交换模型，通往同一个下一跳地点的报文可以用等价转发类的概念来划分，每个等价类走同一路径，用同一种转发策略来处理对应一个流。

在传统的路由决策中，路由器需要对网络数据包进行解包，再根据目的IP地址计算归属的FEC（等价转发类）。而MPLS提出，当网络数据包进入MPLS网络时，对网络数据包进行解包，计算归属的FEC，生成标签（Label）。当网络数据包在MPLS网络中传输时，路由决策都是基于Label，路由器不再需要对网络数据包进行解包。并且Label是个整数，以整数作为key，可以达到O(1)的查找时间。大大减少了路由决策的时间。这里的Label就是MPLS里面的L。需要注意的是Label在MPLS网络里面，是作为网络数据包的一部分，随着网络数据包传输的。

MPLS的核心就是，一旦进入了MPLS网络，那么网络数据包的内容就不再重要，路由决策（包括FEC归属的计算，next hop的查找）都是基于Label来进行的。

**平面和数据流**

* MPLS的数据平面：带标记的报文按交换方式而不是路由方式进行转发、发挥L2转发的效率
* MPLS的控制平面：使用现有的IP控制协议扩展+用于交换标记信息的新协议、发挥L3控制的灵活性和可扩展性
* 四种不同方式的流：
  * 点到点
  * 点到多点
  * 多点到点
  * 多点到多点
* 环路处理三种方式：
  * loop survival
  * loop detection
  * loop prevention

### 数据封装

普通的数据包将基于FIB表转发；若数据包中存在标签号基于LFIB进行转发；

MPLS的数据封装于2层和3层间，故称为2.5层

![mpls-1](mpls-1.png)

### 数据包格式

![mpls-2](mpls-2.png)

* 前20位为标签号：存在2^20个号码，其中0-15号保留；
* 21-23位为8个优先级，用于QOS；
* 第24位为栈底位：为1标示本信息为最后一层标签信息；最多可以存在3层标签；
* 25-32位TTL：当标签号被压入时，将复制3层报头的TTL值，然后每经过一个路由器减1，当标签号弹出时，复制回IP报头中；

### 多层标签

![mpls-3](mpls-3.png)

* 一层标签为普通MPLS，主要用于解决BGP的路由黑洞；
* 二层标签为MPLS VPN使用；
* 三层标签为MPLS TE使用；

使用MPLS后，二层若依然为以太网封装，那么类型号将变化：

* 0x8847 MPLS 单播
* 0x8848 MPLS 多播

### 工作过程

1. 当控制层面使用路由协议传递路由条目后，路由器上使用TDP/LDP为FIB表中每一条存在的路由条目均分配一个标签号，装载于LIB表中，同时传递给邻居，LIB中还记录邻居传递到本地标签号；
2. 之后路由器基于本地的FIB和LIB表生成LFIB（标签转发表）：标签号的最佳路径对应；
3. 数据层面工作时，第一跳路由器负责标签的压入，中间路由器基于标签号转发流量，最后一跳路由器负责标签的弹出；

注：入标签号为本地分配的标号，出标签为下一跳（下游）分配的标签号；存在上下游路由器概念，基于数据层面定义；

## 标记分配协议-LDP

MPLS的一种控制协议

* MPLS标记的指派是由下行节点确定，并通知上行节点（发送方是下行节点，接收方是上行节点），并通知上行节点，同时可以对LSR所允许的标记范围进行限定。
* 在使用LDP进行标记分配时，下行（Rd）LSP执行分配规程、撤销规程；上行(Ru)LSP执行请求规程、不可用规程、释放规程和标记使用规程。
* LDP使用UDP实现发现机制，使用TCP实现其他传输机制。

**LDP规程**

* 分配规程
* 撤销规程
* 请求规程
* 不可用规程
* 释放规程
* 标记使用规程

**LDP分配规程**

* 无条件PUSH：对于路由表中的每一条路由，下行要给上行分配一个标记。
* 有条件PUSH：对于路由表中的路由，如果下行是这条路由的LSP外向节点，或者下行的下行节点已对该路由分配了标记，则下行向对应的上行分配一个标记。
* 无条件PULL：这时针对downstream-on-demand的情况，当上行请求时，下行要分配一个标记。
* 有条件PULL：如果下行满足有条件PUSH的条件，则可响应上行的请求进行标记分配。

## SDN

SDN体系结构：控制层与数据层分离（即控制与转发分离）

SDN控制器：
北向接口面对应用；南向接口面向路由器（南向接口形成事实接口：Openflow…）

SDN要解决的问题：
* “决策者”过多导致全网资源利用率低
* 为不必要的“决策者”付费
* 网络过于复杂

SDN网络面临的问题：
* 北向接口难以统一
* 控制器容易出现单点故障（控制器集群技术）
* 南向接口庞杂
* 难以实现跨域管理和跨域协同（控制器分层）

## 网络功能虚拟化-NFV

核心思想：软件和专用硬件解耦（使得软件和通用硬件结合）

核心技术：管理和编排

网络功能虚拟化：不使用专有设备-需要云服务和SDN技术的支持，需要进行网络功能编排；

## OpenFlow

OpenFlow网络从底到高由三部分组成：
* OpenFlow交换机-实现数据层的转发
* Flow Visor-对网络进行虚拟化
* Controller-对网络集中控制

OpenFlow网络由OpenFlow网络设备（OpenFlow 交换机）、控制器（OpenFlow控制器）、用于连接设备和控制器的安全通道（Secure Channel）以及OpenFlow表项组成。其中，OpenFlow 交换机设备和OpenFlow控制器是组成OpenFlow网络的实体，要求能够支持安全信道和OpenFlow表项。

### 流表

流表是数据转发的依据，与交换机的mac地址转发表和IP地址路由表类似，流表中保存了网络中各个层次的网络配置信息，因此可以进行更加丰富的转发规则。交换机收到来自主机的数据包后，会在本机查询对应的动作，和对应的输出端口。流表有很多流表项，每一条流表项都是一个转发规则。

**流表处理流程**

![flowtable-1](flowtable-1.png)

当报文进入Switch后，必须从最小的Flow Table开始依次匹配。Flow Table可以按次序从小到大越级跳转，但不能从某一Flow Table向前跳转至编号更小的Flow Table。当报文成功匹配一条Flow Entry后，将首先更新该Flow Entry对应的统计数据（如成功匹配数据包总数目和总字节数等），然后根据Flow Table中的指令进行相应操作，比如跳转至后续某一Flow Table继续处理，修改或者立即执行该数据包对应的Action Set等。当数据包已经处于最后一个Flow Table时，其对应的Action Set中的所有Action将被执行，包括转发至某一端口，修改数据包某一字段，丢弃数据包等。具体实现时，OpenFlow交换机还需要对匹配表项次数进行计数、更新匹配集和元数据等操作。

![flowtable-2](flowtable-2.png)

**Table Miss表项**

每个流表（Flow Table）都包含一个Table Miss流表项，该表项用于定义在流表中没有匹配的报文的处理方式，该表项的匹配域为通配，即匹配任何报文，优先级为0，Instructions与正常表项相同。通常，如果Table-Miss表项不存在，默认行为是丢弃报文。

**组表**

OpenFlow组表的表项被流表项（Flow Entry）所引用，提供组播报文转发功能。一系列的Group表项组成了Group Table，每个表项结构如图：

![grouptable](grouptable.png)

根据Group ID可检索到相应Group表项，每个Group表项包含多个动作Bucket，每个Bucket包含多个动作，Bucket内的动作执行顺序依照Action Set的顺序。

**计量表**

Meter计量表项被流表项（Flow Entry）所引用，为所有引用Meter表项的流表项提供报文限速的功能。一系列的Meter表项组成了Meter Table， 每个Meter表项的组织结构如下：

![metertable](metertable.png)

一个Meter表项可以包含一个或者多个Meter Bands，每个Meter Band定义了速率以及动作，报文的速率超过了某些MeterBand，根据这些MeterBand中速率最大的那个定义的动作进行处理。

**安全通道**

OpenFlow设备与Controller通过建立OpenFlow信道，进行OpenFlow消息交互，实现表项下发，查询以及状态上报等功能。通过OpenFlow信道的报文都是根据OpenFlow协议定义的，通常采用TLS（Transport Layer Security）加密，但也支持简单的TCP直接传输。如果安全通道采用TLS连接加密，当交换机启动时，会尝试连接到控制器的6633 TCP端口（Openflow端口通常默认建议设置为6633）。双方通过交换证书进行认证。因此，在加密时，每个交换机至少需配置两个证书。

OpenFlow端口是OpenFlow处理单元与网路其他部分传递封包的网路接口。

一个OpenFlow交换机必须支持三种类型的端口：

* 物理端口
* 逻辑端口
* 保留端口

**标准端口**

OpenFlow标准端口定义为物理端口，逻辑端口以及本地预定的端口。

* 标准端口可以当做入口端口，出口端口来使用。
* 物理端口：OpenFlow的物理端口是与交换机硬件接口对应的由交换机定义的端口。举个例子，以太网交换机上，物理端口与以太网接口一一映射对应。
* 逻辑端口指的是由交换机定义但不与硬件接口直接相关的端口。
* 预定端口：OpenFlow预定端口由RFC文档所定义的。它指明了一般性的转发规则，例如发送给控制器，泛洪或者是使用非OpenFlow的方式转发。

**指令**

每一个流表的表项都包含一系列的指令，当报文匹配上了这个表项后，这些指令就会被执行，这些指令的执行结果有几种：改变报文，改变action set，改变pipeline。这些指令可以按照其执行结果的不同而分类，不同的流表的表项包含的指令种类也不同，前面说了指令可以包含动作，但也并非所有种类的指令都包含动作，下面是指令的分类。

* (可选指令)Meter meter_id，不包含动作，行为是将报文送往指定的meter
* (可选指令)Apply-actions action(s)，这个指令是真正包含动作的指令，它的行为是立即对报文应用这些指令，不要改变报文的action set
* (可选指令)Clear-actions，这个指令并不包含任何的动作，它的行为是立即清除报文的action set中所有的动作
* (必选指令)Write-actions actions(s)，这个指令真正的包含动作，它的行为是将自己包含的动作合并到报文的action set中
* (可选指令)Write-Metadata metadata / mask，这个也不包含动作，用的不多
* (必选指令)Goto-Table next-table-id，这个指令也不包含动作，它表示把报文交给后续的哪张流表处理。OpenFlow协议要求交换机必须支持这个action，但有一个例外是假设你的交换机本身就只支持一张流表，那可以不支持这个action。

**动作**

OpenFlow协议不要求交换机支持所有的动作种类，几个常见的：

* (可选) Output，表示将报文从某个特定的端口送出去
* (必选) Drop，丢弃报文
* (必选) Group，表示将报文交给指定的组
* (可选) Change-TTL，改变报文的TTL字段(可以是IPv4 TTL，MPLS TTL或者Ipv6 Hop Limit)

**Action Set**

Action set是一个与报文相关联的概念，只要提起action set，它就一定是报文的action set，它包含了当报文离开流表时要附加于这个报文上的动作。我们前面看到了有一种Apply-actions指令，它是在报文匹配了表项的时候将它包含的动作立即应用到报文上，而Write-actions则是将它包含的动作合并到报文的action set中，另外还有Clear-actions指令，是将报文的action set清空。最终报文走完所有流表时，其action set里面有什么动作，就执行什么动作，这就是action set的作用了。

**Action List**

Action list实际上就是一系列动作的有序序列，一定要注意其有序性。在上面说到的流表中的Apply-actions指令中，以及OpenFlow协议中同样能够包含动作的Packet-out命令中，都要求所包含的动作被有序执行。所以就出来了这么个action list的概念，这是与action set的一点区别。另一个区别是action list并不是和报文相关联的概念，action list可以直接夹带在 controller发给agent的消息中，比如Packet-out消息；也可以存在于流表表项的指令中，比如Apply-actions指令。

### 三种报文类型

* Controller to Switch消息
  * 由Controller发起、Switch接收并处理的消息。这些消息主要用于Controller对Switch进行状态查询和修改配置等管理操作，可能不需要交换机响应。
* 异步（Asynchronous）消息
  * 由Switch发送给Controller，用来通知Switch上发生的某些异步事件的消息，主要包括Packet-in、Flow-Removed、Port-Status和Error等。例如，当某一条规则因为超时而被删除时，Switch将自动发送一条Flow-Removed消息通知Controller，以方便Controller作出相应的操作，如重新设置相关规则等。
* 同步（Symmetric）消息
  * 顾名思义，同步（Symmetric）消息是双向对称的消息，主要用来建立连接、检测对方是否在线等，是控制器和OpenFlow交换机都会在无请求情况下发送的消息，包括Hello、Echo、Error和Experimenter四种消息。

## 信道建立过程

OpenFlow控制器和OpenFlow交换机之间建立信道连接的基本过程，具体步骤如下：

1. OpenFlow交换机与OpenFlow控制器之间通过TCP三次握手过程建立连接，使用的TCP端口号为6633。
2. TCP连接建立后，交换机和控制器就会互相发送hello报文。Hello报文负责在交换机和控制器之间进行版本协商，该报文中OpenFlow数据头的类型值为0。
3. 功能请求（Feature Request）：控制器发向交换机的一条OpenFlow 消息，目的是为了获取交换机性能，功能以及一些系统参数。该报文中OpenFlow 数据头的类型值为5。
4. 功能响应（Feature Reply）：由交换机向控制器发送的功能响应（Feature Reply）报文，描述了OpenFlow交换机的详细细节。控制器获得交换机功能信息后，OpenFlow协议相关的特定操作就可以开始了。
5. Echo请求（Echo Request）和Echo响应（EchoReply）属于OpenFlow中的对称型报文，他们通常用于OpenFlow交换机和OpenFlow控制器之间的保活。通常echo请求报文中OpenFlow数据头的类型值为2，echo响应的类型值为3。不同厂商提供的不同实现中，echo请求和响应报文中携带的信息也会有所不同。

**流表下发**

OpenFlow流表下发分为主动和被动两种机制：

* 主动模式下，Controller将自己收集的流表信息主动下发给网络设备，随后网络设备可以直接根据流表进行转发。
* 被动模式下，网络设备收到一个报文没有匹配的FlowTable记录时，会将该报文转发给Controller，由后者进行决策该如何转发，并下发相应的流表。被动模式的好处是网络设备无需维护全部的流表，只有当实际的流量产生时才向Controller获取流表记录并存储，当老化定时器超时后可以删除相应的流表，因此可以大大节省交换机芯片空间。

在实际应用中，通常是主动模式与被动模式结合使用。

**交换机报文上送控制器**

![openflow-1](openflow-1.png)

**控制器回应报文**

![openflow-2](openflow-2.png)

## QoS

QoS（Quality of Service，服务质量）指一个网络能够利用各种基础技术，为指定的网络通信提供更好的服务能力，是网络的一种安全机制， 是用来解决网络延迟和阻塞等问题的一种技术。

QoS基本测度：

* 带宽
* 延迟
* 丢包率
* 可用性
* 稳定性

## 拥塞

网络或其一部分由于超载而引起性能严重下降的现象称为拥塞。

拥塞原因：

* 资源相对不足
* 过多的突发报文
* 系统处理能力不足
* 重传处理不当
* 路由不合理

拥塞控制的目的：避免全局同步，超过崖点的吞吐量急剧下降，网络负载小于knee时，网络能及时处理到达的流量。

拥塞处理方式：拥塞控制（对已经发生的网络过载作出反应避免拥塞）；拥塞避免（网络过载前检测和避免）

拥塞控制与资源分配：网络的关键是将其传输资源分配给用户或应用

## 资源分配

两个极端：

* 让网络来分配资源：分配资源很困难，很可能浪费资源
* 让资源发送他们想要的数据：可以从拥塞发生中恢复，易于实现，但是可能会丢包

资源分配基本方式：
依据处理对象（主机/路由器）；依据分配时间（传输前预留资源/传输中动态调整资源）；依据使用策略（窗口机制/依据接收者能力确定资源）

资源分配评价标准：有效性（吞吐量尽量大，延迟尽量小）；公平性（合理但不一定均匀分配）

## 队列管理

队列管理机制：

* FIFO方法（缺省方式，先来先服务，队列长度有限，溢出丢弃）
* 优先队列（按优先级排队，有区别处理用户需求，处理代价高于FIFO）
* 随机公平队列SFQ（用hash函数将源宿地址映射到队列，hash函数需常更换）
* 类别队列CBQ（将服务映射到队列，可以避免某服务完全被拒绝，类似于优先队列）
* 加权公平队列WFQ（加权方式分配资源，可区分不同用户的流，可给一些队列高优先级）

**主动队列管理（Active Queue Management，AQM）**

路由器中最常用的队列管理策略是“队尾丢弃”。它是一种拥塞恢复机制，能够维持Internet 的稳定运行，但是存在着满队列、死锁以及全局同步等问题。在此基础上改进的“首丢弃”和“随机丢弃”对死锁和全局同步是有效的，但没有解决持续的满队列问题。AQM 不是队列满才开始丢弃数据包，是一种主动拥塞控制机制，可以有效地解决“全局同步”问题。AQM 通常利用当前的队列长度等拥塞信息来控制中间节点队列。由于网络存在传输时间滞后，采样所得的队列长度等拥塞信息，是反映一段时间之前的网络状况。当拥塞信息被反馈至发送端时，又增加了额外的延迟时间，所以AQM存在响应相对滞后于实际网络状况的缺陷。另外AQM 还存在参数设置敏感的缺陷，在不同的网络状况很难保持其性能。为了维持队列长度稳定、减少排队时延并降低丢包率，主动队列管理总是提前丢包通知发送端降低发送速度，同样会导致中间节点的传输效率下降。可见主动队列管理是牺牲部分网络传输效率来获得低时延、队列长度稳定等性能。

**为什么选择主动队列管理**

* 锁定延时问题：drop-tail（队尾丢弃）允许一些流独占队列空间，锁定其他流
* 完整队列问题：drop tail可能在拥塞期间保持完整或者接近完整的队列
* Lock-out问题解决：
  * 随机丢弃
  * 丢弃前面的
  * 丢弃不合适的
* Full Queues问题解决：
  * 队列变满之前丢弃数据包（丢弃早期的）
  * 预先通知发送者阻塞（RED）

## WRED（加权随机早期探测）

在网络发生拥塞的时候，默认的是尾丢弃，我们不希望这样，我们总是希望先丢弃优先级低的数据包，而保证优先级高的数据包的发送，WRED是基于权重的随机早侦测，工作思想和WFQ有相同之处，因为WFQ在工作时，是依靠流量的优先级来分配相应带宽的，而WRED却是依靠流量的优先级来分配相应的丢弃几率的。

## CHOKe

将新数据包与队列中的随机数据包进行比较；如果来自同一流程，则全丢弃，否则使用RED来决定新数据包的下一步动作。这种方法可以寻找占用资源较多的流，即同时被选中两个或以上报文的概率更大。该方法针对恶意流，因此每到达一个，就丢弃两个或更多，使恶意流在队列中逐渐减少。

## 接纳控制

接纳控制是一个网络QoS过程，它决定了如何为具体不同需求的流分配带宽和延迟，通常以流为整体单位进行整体调节。（基于策略或基于现状）

## DEC-bit（基于反馈的拥塞控制机制）

* 基本思想：在拥塞时路由器在数据包上设置一个位，在确认中接收端发送的中继位，发送端使用反馈来调整发送速率。
* 来源：信号过滤，发送方如何响应
* 关键问题：路由器何时、如何发送反馈

## TCP拥塞控制

TCP的拥塞控制主要原理依赖于一个拥塞窗口(cwnd)来控制，在之前我们还讨论过TCP还有一个对端通告的接收窗口(rwnd)用于流量控制。

窗口值的大小就代表能够发送出去的但还没有收到ACK的最大数据报文段，显然窗口越大那么数据发送的速度也就越快，但是也有越可能使得网络出现拥塞，如果窗口值为1，那么就简化为一个停等协议，每发送一个数据，都要等到对方的确认才能发送第二个数据包，显然数据传输效率低下。TCP的拥塞控制算法就是要在这两者之间权衡，选取最好的cwnd值，从而使得网络吞吐量最大化且不产生拥塞。

由于需要考虑拥塞控制和流量控制两个方面的内容，因此TCP的真正的发送窗口=min(rwnd, cwnd)。但是rwnd是由对端确定的，网络环境对其没有影响，所以在考虑拥塞的时候我们一般不考虑rwnd的值，我们暂时只讨论如何确定cwnd值的大小。关于cwnd的单位，在TCP中是以字节来做单位的，我们假设TCP每次传输都是按照MSS大小来发送数据的，因此你可以认为cwnd按照数据包个数来做单位也可以理解，所以有时我们说cwnd增加1也就是相当于字节数增加1个MSS大小。  

**标准TCP问题**

标准TCP将网络丢包的原因归结为拥塞，而忽略链路错误造成的丢包，这在高速网络环境中是不可取的。而传统的拥塞控制算法为了保证其公平性，采用了“加性增乘性减”（AIMD）拥塞控制思想，一旦丢包发生，窗口便被大幅度减少，这使得在存在丢包的高速环境中，即使理论带宽再大，实际带宽最终只能收敛到一个小值。同时现代网络中间设备为解决流量突发问题（短时接收速率＞发送速率），都存在较大的流量缓存功能，缓存队列的增加将导致报文RTT变大。

TCP的拥塞控制分为两类：基于时延（BBR为代表）；基于丢包（CUBIC为代表）。

**TCP的Delayed ACK机制**

* 为了节约发送ACK报文所耗费的资源，数据的接收端按如下方式进行ACK报文响应：
  * 一般情况下延迟窗口为2，接收端收到了第2个数据报文后发送ACK报文；
  * 如果接收端等待的时间超过了Delayed ACK的超时阈值，接收端改为对每个收到的报文发送ACK；
  * 接收端发现丢包后将延迟窗口设为1，对每个到达的报文发出一个ACK，直到收到所有丢失的报文，再将延迟窗口设为2。
* Nagle算法：当数据以每次一个字节的方式进入发送方时，发送方只发送第一个字节，然后将其他的字节缓冲起来，直到送出去的那个字节被确认为止，然后将所有缓冲的字节放在一个TCP数据段中发送出去，并且开始继续缓冲字节，直到前面发送出去的字节全部被确认。（面向虚拟终端类应用）

**基本概念**

* 段：任意TCP报文
* 发送方最大段长（SMSS）：发送方能发送的最大数据长度（不包括报头），与MTU和RMSS等因素有关
* 接收方最大段长（RMSS）：接收方能接收的最大数据长度（不包括报头），这个参数在连接建立时约定，缺省为536B
* 全长段：数据长度为SMSS的报文
* 接收窗口（RWND）：由接收者最新确认的窗口长度（实际的接收端缓冲长度），由接收到的ACK决定
* 拥塞窗口（CWND）：给出当前网络可接受的最大数据量，它表达了数据发送方在收到接收方发来的ACK报文之前，可向网络发送的数据量的上限，其大小由TCP的拥塞控制算法决定。它用来限制TCP数据发送的状态变量，使得在任意时刻有：
  * 发送数据的序列号 ≤ 最大应答序列号 + min{CWND, RWND}
  * CWND的初始上限不能超过接收方的窗口长度，但其值将随数据的发送情况使用不同的方法来调整
  * CWND根据对ACK报文的接收情况进行变化，但CWND不会小于一个最大报文长度（MSS）
* 慢启动阈值（ssthresh）：它决定使用何种方法来调整CWND的值，这是拥塞控制中慢启动阶段和拥塞避免阶段的分界点。
  * 如果CWND < ssthresh，使用慢启动算法增加CWND的值，否则使用拥塞避免算法
* 飞行长度：已经发送但尚未确认的数据长度

### 慢启动与拥塞避免

**慢启动**

最初的TCP在连接建立成功后会向网络中发送大量的数据包，这样很容易导致网络中路由器缓存空间耗尽，从而发生拥塞。因此新建立的连接不能够一开始就大量发送数据包，而只能根据网络情况逐步增加每次发送的数据量，以避免上述现象的发生。

具体来说，当新建连接时，cwnd初始化为1个最大报文段(MSS)大小，发送端开始按照拥塞窗口大小发送数据，每当有一个报文段被确认，cwnd就增加1个MSS大小。这样cwnd的值就随着网络往返时间(Round Trip Time,RTT)呈指数级增长，事实上，慢启动的速度一点也不慢，只是它的起点比较低一点而已。如果带宽为W，那么经过RTT*log2W时间就可以占满带宽。  

**拥塞避免**

从慢启动可以看到，cwnd可以很快的增长上来，从而最大程度利用网络带宽资源，但是cwnd不能一直这样无限增长下去，一定需要某个限制。TCP使用了一个叫慢启动门限(ssthresh)的变量，当cwnd超过该值后，慢启动过程结束，进入拥塞避免阶段。对于大多数TCP实现来说，ssthresh的值是65536(同样以字节计算)。拥塞避免的主要思想是加法增大，也就是cwnd的值不再指数级往上升，开始加法增加。此时当窗口中所有的报文段都被确认时，cwnd的大小加1，cwnd的值就随着RTT开始线性增加，这样就可以避免增长过快导致网络拥塞，慢慢的增加调整到网络的最佳值。  

**具体流程**

当一个主机开始向一个TCP连接发送数据时，主机并不知道它与接收方之间的网络状态，需要对网络容量进行试探。为了避免发送过大的报文，使得网络一开始就发送阻塞，TCP在开始数据传输时使用慢启动算法。慢启动和拥塞避免算法可用来控制TCP的飞行长度，其受到CWND和RWND的制约。

慢启动基本思想：主机发送了一个报文后要停下来等待应答。每收到一个应答，CWND的值就增加一段的长度，直到CWND的值等于ssthresh的值，或网络发生了报文丢失。慢启动期间CWND的增长将随RTT呈指数级增长。初始时：

$$
CWND = IW ≤ min{2 * SMSS, 2 * 段长}
$$

当CWND ≥ ssthresh时，使用拥塞避免算法来调整CWND的值。这时用加法递增的来递增CWND，其目的是试探网络是否还有更多的容量可供使用：

$$
CWND += SMSS * SMSS / CWND
$$

### 快速重发和快速恢复

TCP通常使用基于RTT的重发计时器来检查是否有报文丢失，若超时而未收到应答则要进行重发。另外接收方可能收到失序的报文，这时它要返回已收到的有序报文的最大序列号，而这个应答序列号应该是已发送过的，因此发送方会收到重复的应答序列号。为了提高传输效率，TCP发送方在收到重复的应答时使用快速重传算法和快速恢复算法来检测和修复丢失的数据，而快速重传算法要求发送方在收到3个相同的重复应答后立即启动重传，而不必等到重传计时器超时。

首先来看TCP是如何确定网络进入了拥塞状态的，TCP认为网络拥塞的主要依据是它重传了一个报文段。上面提到过，TCP对每一个报文段都有一个定时器，称为重传定时器(RTO)，当RTO超时且还没有得到数据确认，那么TCP就会对该报文段进行重传，当发生超时时，那么出现拥塞的可能性就很大，某个报文段可能在网络中某处丢失，并且后续的报文段也没有了消息，在这种情况下，TCP反应比较“强烈”：

1. 把ssthresh降低为cwnd值的一半
2. 把cwnd重新设置为1
3. 重新进入慢启动过程。

从整体上来讲，TCP拥塞控制窗口变化的原则是AIMD原则，即加法增大、乘法减小。可以看出TCP的该原则可以较好地保证流之间的公平性，因为一旦出现丢包，那么立即减半退避，可以给其他新建的流留有足够的空间，从而保证整个的公平性。具体来说快速恢复的主要步骤是：

1. 当收到3个重复ACK时，把ssthresh设置为cwnd的一半，把cwnd设置为ssthresh的值加3，然后重传丢失的报文段，加3的原因是因为收到3个重复的ACK，表明有3个“老”的数据包离开了网络。
2. 再收到重复的ACK时，拥塞窗口增加1。
3. 当收到新的数据包的ACK时，把cwnd设置为第一步中的ssthresh的值。原因是因为该ACK确认了新的数据，说明从重复ACK时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态。

快速重传算法首次出现在4.3BSD的Tahoe版本，快速恢复首次出现在4.3BSD的Reno版本，也称之为Reno版的TCP拥塞控制算法。  

可以看出Reno的快速重传算法是针对一个包的重传情况的，然而在实际中，一个重传超时可能导致许多的数据包的重传，因此当多个数据包从一个数据窗口中丢失时并且触发快速重传和快速恢复算法时，问题就产生了。因此NewReno出现了，它在Reno快速恢复的基础上稍加了修改，可以恢复一个窗口内多个包丢失的情况。具体来讲就是：Reno在收到一个新的数据的ACK时就退出了快速恢复状态了，而NewReno需要收到该窗口内所有数据包的确认后才会退出快速恢复状态，从而更一步提高吞吐量。  

### SACK选择性应答

SACK就是改变TCP的确认机制，最初的TCP只确认当前已连续收到的数据，SACK则把乱序等信息会全部告诉对方，从而减少数据发送方重传的盲目性。比如说序号1，2，3，5，7的数据收到了，那么普通的ACK只会确认序列号4，而SACK会把当前的5，7已经收到的信息在SACK选项里面告知对端，从而提高性能，当使用SACK的时候，NewReno算法可以不使用，因为SACK本身携带的信息就可以使得发送方有足够的信息来知道需要重传哪些包，而不需要重传哪些包 

**高速信道问题**

信道很难保持在满负荷，另外TCP与AIMD表现出的RTT unfairness为$(RTT2 / RTT1)*2 - 马太效应$，为了提高发送速率应该使得RTT尽量小，CWND尽量大。

**BIC(Binary Increase Congestion control)**

BIC将拥塞避免阶段的线性遍历算法改成二分搜索算法，它基于以下的事实：
* 如果发生丢包的时候，窗口的大小是W1，那么要保持线路满载却不丢包，实际的窗口最大值应该在W1以下；
* 如果检测到发生丢包，并且已经将窗口乘性减到了W2，那么实际的窗口值应该在W2以上。

因此，在TCP快速恢复阶段过去之后，便开始在W2~W1这个区间内进行二分搜索，寻找窗口的实际最大值。于是定义W1为Wmax，定义W2为Wmin。

那么如何驱动整个二分搜索的过程呢？采用ACK驱动：每收到一个ACK的时候，便将窗口设置到Wmax和Wmin的中点，一直持续到接近Wmax。

## CUBIC

使用一个3次函数来确定拥塞窗口的大小，且与RTT无关。基于丢包做拥塞控制，常导致瓶颈路由器大量报文丢失。随着内存的不断降价，路由器设备的缓冲队列也会越来越大，CUBIC算法会造成更大的RTT时延！

**CUBIC整体架构调用的逻辑如下**

1. 连接每收到一个ack，则调用tcp_ack
2. tcp_ack会调用bictcp_acked，用来更新cnt和delayed_ack（用来消除delay包的影响）
3. tcp_ack会调用bictcp_cong_avoid，这是分两种情况：
   1. snd_cwnd小于慢启动阈值，处于慢启动阶段，则调用tcp_slow_start
   2. snd_cwnd大于慢启动阈值，处于拥塞避免阶段，则调用bictcp_update来更新bictcp，再调用tcp_cong_avoid_ai
4. tcp_ack中如果检测到丢包，进入拥塞处理阶段，则调用bictcp_recalc_ssthresh来更新慢启动阈值
5. tcp_ack中完成丢包重传后，退出拥塞处理阶段，则调用bictcp_undo_cwnd来更新snd_cwnd

CUBIC在设计上简化了BIC-TCP的窗口调整算法，在BIC-TCP的窗口调整中会出现一个凹和凸(这里的凹和凸指的是数学意义上的凹和凸，凹函数/凸函数)的增长曲线，CUBIC使用了一个三次函数(即一个立方函数)，在三次函数曲线中同样存在一个凹和凸的部分，该曲线形状和BIC-TCP的曲线图十分相似，于是该部分取代BIC-TCP的增长曲线。另外，CUBIC中最关键的点在于它的窗口增长函数仅仅取决于连续的两次拥塞事件的时间间隔值，从而窗口增长完全独立于网络的时延RTT，之前讲述过的HSTCP存在严重的RTT不公平性，而CUBIC的RTT独立性质使得CUBIC能够在多条共享瓶颈链路的TCP连接之间保持良好的RRTT公平性。

来看下具体细节：当某次拥塞事件发生时，Wmax设置为此时发生拥塞时的窗口值，然后把窗口进行乘法减小，乘法减小因子设为β，当从快速恢复阶段退出然后进入到拥塞避免阶段，此时CUBIC的窗口增长开始按照“凹”式增长曲线进行增长，该过程一直持续直到窗口再次增长到Wmax，紧接着，该函数转入“凸”式增长阶段。该方式的增长可以使得窗口一直维持在Wmax附近，从而可以达到网络带宽的高利用率和协议本身的稳定性。

窗口的增长函数如下：$W(t) = C * (t-K)3 + Wmax$, 其中C和β为常量，t为当前时间距上一次窗口减小的时间差，而K就代表该函数从W增长到Wmax的时间周期。

当收到ACK后，CUBIC计算利用该算法计算下一个RTT内的窗口增长速度，即计算W(t+RTT)，该值将作为cwnd的目标值，根据cwnd的大小，CUBIC将进入三种不同模式，如果cwnd会小于在标准TCP下经过上次拥塞之后的时刻t窗口将会达到的值(该值是通过标准TCP的窗口增长函数计算出来的)，那么CUBIC就处于标准TCP模式，如果小于Wmax，那么位于凹阶段的，如果大于Wmax，那么处于凸阶段。

**基于时延探测的拥塞控制**

* 任何时候一个全双工的TCP连接在每个方向都有一跳最慢的链路（瓶颈），它：
  * 决定该连接的最大数据交付速率；
  * 在该点形成persistent queue，下游速率加快时队列缩短，上游速率加快时队列加长；
  * 排队产生时延，隐藏大缓存使得丢包少但是RTT增大。
* 不管这个TCP连接由多少跳构成，以及各跳的容量如何，整个通路可看成是一个链路，具有两个限制传输性能的物理约束。

## BBR

GOOGLE提出的新拥塞控制算法

**BBR对标准TCP问题的解决方式**

* 不再将丢包作为拥塞判断的一部分。TCP从SACK开始就提出将拥塞控制和选择重传机制分离，bbr也遵循了这一思想。
* 因为最优带宽和延迟无法同时测量（btlBw的测量会造成存在网络缓存增加RTT，而RTprop的测量要求网络缓存为空），所以分别估计带宽（btlBw）和延迟（RTprop），最后计算出cwnd。同时增加变量pacing rate（btlBw * 增益系数），用于控制发送端的发送速率，以解决发送端突发造成的网络排队问题。

**组成**

1. 即时速率的计算：计算一个即时的带宽bw，该带宽是bbr一切计算的基准，bbr将会根据当前的即时带宽以及其所处的pipe状态来计算pacing rate以及cwnd(见下文)，后面我们会看到，这个即时带宽计算方法的突破式改进是bbr之所以简单且高效的根源。计算方案按照标量计算，不再关注数据的含义。在bbr运行过程中，系统会跟踪当前为止最大的即时带宽。
2. RTT的跟踪：bbr之所以可以获取非常高的带宽利用率，是因为它可以非常安全且豪放地探测到带宽的最大值以及rtt的最小值，这样计算出来的BDP就是目前为止TCP管道的最大容量。bbr的目标就是达到这个最大的容量！这个目标最终驱动了cwnd的计算。在bbr运行过程中，系统会跟踪当前为止最小RTT。
3. BBR状态机的维持：bbr算法根据互联网的拥塞行为有针对性地定义了4中状态，即STARTUP，DRAIN，PROBE_BW，PROBE_RTT。bbr通过对上述计算的即时带宽bw以及rtt的持续观察，在这4个状态之间自由切换，相比之前的所有拥塞控制算法，其革命性的改进在于bbr拥塞算法不再跟踪系统的TCP拥塞状态机，而旨在用统一的方式来应对pacing rate和cwnd的计算，不管当前TCP是处在Open状态还是处在Disorder状态，抑或已经在Recovery状态，换句话说，bbr算法感觉不到丢包，它能看到的就是bw和rtt！
4. 结果输出-pacing rate和cwnd：首先必须要说一下，bbr的输出并不仅仅是一个cwnd，更重要的是pacing rate。在传统意义上，cwnd是TCP拥塞控制算法的唯一输出，但是它仅仅规定了当前的TCP最多可以发送多少数据，它并没有规定怎么把这么多数据发出去，在Linux的实现中，如果发出去这么多数据呢？简单而粗暴，突发！忽略接收端通告窗口的前提下，Linux会把cwnd一窗数据全部突发出去，而这往往会造成路由器的排队，在深队列的情况下，会测量出rtt剧烈地抖动。bbr在计算cwnd的同时，还计算了一个与之适配的pacing rate，该pacing rate规定cwnd指示的一窗数据的数据包之间，以多大的时间间隔发送出去。
5. 其它外部机制的利用-fq，rack等：bbr之所以可以高效地运行且如此简单，是因为很多机制并不是它本身实现的，而是利用了外部的已有机制，比如下一节中将要阐述的它为什么在计算带宽bw时能如此放心地将重传数据也计算在内

**bbr pipe状态机的维持**

bbr算法根据互联网的拥塞行为有针对性地定义了4种状态，即STARTUP，DRAIN，PROBE_BW，PROBE_RTT。bbr通过对上述计算的即时带宽bw以及rtt的持续观察，在这4个状态之间自由切换，相比之前的所有拥塞控制算法，其革命性的改进在于bbr拥塞算法不再跟踪系统的TCP拥塞状态机，而旨在用统一的方式来应对pacing_rate和cwnd的计算，不管当前TCP是处在Open状态还是处在Disorder状态，抑或已经在Recovery状态，换句话说，bbr算法感觉不到丢包，它能看到的就是bw和rtt！

**拥塞控制实现**

BBR通过检测RTprop和BtlBw来实现拥塞控制。什么是RTprop呢？这是链路的物理时延，因为RTT里含有报文在路由器队列里的排队时间、ACK的延迟确认时间等。什么叫延迟确认呢？TCP每个报文必须被确认，确认动作是通过接收端发送ACK报文实现的，但由于TCP和IP头部有40个字节，如果不携带数据只为发送ACK网络效率过低，所以会让独立的ACK报文等一等，看看有没有数据发的时候顺便带给对方，或者等等看多个ACK一起发。

RTT我们可以测量得出，RTprop呢，我们只需要找到瓶颈路由器队列为空时多次RTT测量的最小值即可。

而BtlBw全称是bottleneck bandwith，即瓶颈带宽，我们可以通过测量已发送但未ACK确认的飞行中字节除以飞行时间deliveryRate来测量。

**BBR状态**

* Startup状态：这是bbr的加速阶段，类似于慢启动阶段，startup以指数的增益速度增加发送速率，希望快速探测到Btlbw瓶颈带宽，这里的增益系数为2/ln2。
* Drain：DRAIN阶段存在的意义，是为了排空STARTUP阶段造成的网络缓存，使inflight大小等于BDP。在该阶段，bbr使用一个小的增益系数（STARTUP状态增益系数的倒数）计算pacing rate和cwnd，使得网络队列缓存被迅速排空。
* PROBE_BW：该状态是BBR的一个稳定状态，BBR的大部分时间都在该状态运行，当BBR测量到瓶颈带宽和最小rtt，并且inflight等于BDP后，便开始以一个稳定的匀速维护着网络状态，偶尔小幅提速探测是否有更大带宽，偶尔小幅降速公平的让出部分带宽，即使用gain cycling方法进行带宽测试。
* PROBE_RTT：如果BBR处于稳态且RTProp超过10秒没有降低，则进入该状态。该状态下，cwnd被设置为4个MSS，并对RTT重新测量，持续200ms，超时后，根据网络带宽是否满载决定状态切换为Startup或PROBE_BW。

![bbr](bbr.jpg)

* BDP带宽时延积：表示了单位时间通过能力与通过所需的时间之积，即在途的数据量，即inflight。
* 流的公平性控制：ProbeBW阶段使用gain循环来使大流快速向小流让出带宽，导致各个流可在几个循环周期内获得带宽公平。
* 流的稳定性控制：BBR将cwnd gain × BDP设为当前CWND的上限，限制过多报文的发送。如果遇到重发超时，则发送方认为所有的inflight报文丢失。这时BBR将CWND降为1，与CUBIC处理方式一致。
* 即时带宽的计算：bbr作为一个纯粹的拥塞控制算法，完全忽略了系统层面的TCP状态，计算带宽时它仅仅需要两个值就够了。应答了多少数据，记为delivered；应答delivered这么多数据所用的时间，记为interval_us；将上述二者相除，就能得到带宽：bw = delivered/interval_us

**BBR优势**

* 如果收到重复ACK(重复ACK，SACKed数量，SACKed最高值…)，虽然TCP核心认为发生了丢包，但是不会进入PRR，BBR会不屑一顾，继续自己的策略，参见BBR引擎说明书；
* 如果真的发生了拥塞，BBR在最小RTT周期之后会发现这是真的，虽然滞后，但总比CUBIC之类滞后发现第二类缓存被填满强多了。BBR不会盲目降速，而是依然根据检测到的max-BW来，除非max-BW已经非常小！
* 如果发生监管丢包，BBR会在一段比较长的周期内检测到，它发现在这个周期内持续持有比较高的丢包率(检测到的Lost计数器偏大)，且速率保持一致，那么BBR会将发送量限制在实际带宽的平均值。

**BBR vs CUBIC**

* BBR的Startup与CUBIC的slow start相比，前者不受丢包或时延增加的影响（即使丢包也不离开Startup状态），因此更为鲁棒。此外，BBR是平滑地连续发送报文，而CUBIC是断续式发送，受ACK报文的限制。
* BBR比CUBIC更加保守，发现产生排队就限速，而不是等丢包了才限速。
* 由于丢包少且时延小，因此BBR比CUBIC效率更高。
* 驱动方法不同
  * Reno/CUBIC：它们是事件驱动的！无论是丢包，还是RTT增加，都被视为一种严重的事件，这些严重的事件导致TCP拥塞控制系统在”To find current bandwidth“，”To avoid congestion“以及”To probe more bandwidth“之间切换，最终落实下来的就是促使拥塞算法(无论Reno，Vegas还是CUBIC)调整窗口的大小。那么谁来发现这些事件是否发生呢？答案是TCP拥塞控制状态机。拥塞控制状态机直接主导这些状态的切换，只要它发现丢包，不管是不是真的，都会拉低窗口值。所以说，Reno/CUBIC的窗口调整是被动的。
  * bbr是反馈驱动的！bbr内置了自主的调速机制，不受TCP拥塞控制状态机的控制，bbr算法是自闭的，它可以自己完成VJ的所有状态探测以及切换，无需外界干涉，且对外界的干涉视而不见。bbr周期性的试图探测是否有更多的带宽，如果有，那么就利用它，如果没有，就退回到之前的状态。所以说，bbr的窗口调整是主动的。

## IntServ集成服务

面向传输路径，引入了虚拟连接的概念。带宽资源必须经过显示的分配和管理才能满足应用的服务质量需要：因此有资源预留和准入控制。

通信一般从功能角度可以分为两大类：有时延要求（视频通信）、无时延要求

**RSVP资源预留协议**

是一种用于互联网上质量整合服务的协议。RSVP协议允许主机在网络上请求特殊服务质量用于特殊应用程序数据流的传输。路由器也使用RSVP发送服务质量(QOS)请求给所有结点(沿着流路径)并建立和维持这种状态以提供请求服务。通常RSVP请求将会引起每个节点数据路径上的资源预留。

* 基于流：端到端的质量服务保证RSVP（带宽时延抖动有量化规定）
* 基于相关状态：可控负载型服务（负载不会超过token）

**集成服务的局限性**

* 基于流的RSVP资源预留、调度处理以及缓冲区管理有利于提供QoS保证，但使系统开销过高，对于大型网络存在可扩展性问题和鲁棒性问题。
* 目前只有少量主机支持RSVP信令，大量现有的应用不支持，推广困难。
* 提供QoS保证的IntServ具有某种面向连接的特性，而IP网络的发展仍不具有面向连接的特性。
* 必要的政策控制（如AAA：认证、授权、记账）和pricing机制尚处于发展阶段，无法应用。
* 目前主要用作为MPLS的信令协议，支持流量工程和带QoS的LSP建立。

## DiffServ区分服务

通过服务类别体现网络服务质量的差别，将用户流按服务类别聚类，以降低管理开销。
-区分服务是一种面向大规模网络的Class-Of-Service机制，用户数据可以在进入网络前提出自己的传输质量要求，网络服务提供者也可以提出可提供的服务质量（和代价）供用户选择。
-DS为NSP提供一种框架，使其可按各个用户所需的不同性能和价格来向他们提供不同服务。

**区分服务体系结构分层**

DS domain（管理者）和DS region（不同子网）；换管理者后，金牌银牌可能是不一样的，所以需要打通，是加钱换金牌服务，还是降级为银牌服务。

**区分服务体系结构基本模型**

* 在网络边界对IP报头设置不同比特；
* 网络边缘节点根据这些比特对报文进行分类和调节，并指派给一个行为聚合（BA）。
* 每个行为聚合用一个DS CodePoint标识，这样报文在网络中进行转发时，要按其DSCP中定义的PHB进行处理。

## Hop-by-hop transport

逐跃传输是控制网络中数据流的原则。使用按跃点传输，数据块以存储和转发的方式从节点转发到节点。由于按跃点传输不仅涉及源节点和目标节点，还涉及部分或所有中间节点，因此即使源节点和目标之间的路径在通信期间未永久连接，也允许转发数据。

但是，端到端原则主张，除非实现按跃得传输实现更好的性能，否则应端到端地实施传输控制。此外，逐跃传输要求在中间节点上提供每流状态信息，这限制了其可伸缩性。这就是为什么现在几乎所有的通信都由端到端传输协议（如TCP）控制的原因之一。

目前在稀疏移动网络领域的研究正在考虑对仅间歇性提供端到端连接的应用方案进行跳点传输，因为在这种情况下，按跳次传输可以带来可观的性能提升。

## TOS（type of service）

服务类型（TOS）(8 bit)字段包括一个3 bit的优先权子字段（取值可以从000-111所有值），4 bit的TOS子字段和1 bit未用位但必须置0。4 bit的TOS分别代表：最小时延、最大吞吐量、最高可靠性和最小费用。4 bit中只能置其中1 bit。如果所有4 bit均为0，那么就意味着是一般服务。

TOS常用来实现QOS，用于在数据传输过程中的质量保证。说通俗一点，路窄、车多，所以对车标出优先级，有些车先走，有些车后走，有些车不让走。路由器跟交警一样，指挥交通，如何操作，取决事先确定的策略。对于终端而言（比如电脑），已经收到报文，所以就不会关心这个字段。

**CoS与QoS不同**

* QoS根据带宽或者传输时间(如带宽优先级或流量整形)来划分服务等级，而CoS则是利用流量的传输优先级。
* 支持IP的帧中继和ATM网络可以使用户充分地利用QoS和CoS技术所带来的好处；通过CoS，用户可以实现穿过整个网络的端到端的优先级分配和传输，而对于专用网络来说，由于服务提供商拥有整个网络，因此可以保证整个网络的优先级实施。

**CoS的工作过程如下**

* 首先，在每个连接的终端，CoS根据各种应用的需要为每个IP数据分组头设置区别服务Diff-Serv代码，也就是为数据分组设置优先级。网络数据的管理由用户来完成，Diff-Serv只是用来对数据进行划分优先级的协议。根据用户网络的不同，经过了优先级划分的IP分组被封装成帧中继或者ATM信元，并在用户的网络上传输。
* 数据穿过用户网络后到达入口交换机，在那里帧中继或ATM信元被解封成为下行IP分组。入口交换机根据用户流量的需要测量下行数据流量，并根据不同流量类型的优先级以适当的顺序组装这些数据分组。
* 之后，数据被包裹到多协议标签交换MPLS分组中，在运行MPLS的核心网络中传输。核心网络中的交换机可以保证数据的优先级服务并最终将数据转送给出口交换机，出口交换机再将MPLS分组解包成IP分组。
* 在用户的出口接口处，IP分组按照最初的顺序重新调整后被封装成帧中继或者ATM信元，信元通过回路最后传输到用户的设备。用户设备将分组再转换成IP数据并根据它们的优先级发送出去。

## 路由

**基本原理**

* 路由是使用routing protocal在routed protocal数据的源点和终点之间确定传输路径的过程。
* 路由器相互交换路由消息以推断到其他逻辑网络的路径
  * 基于某些标准的测度选择从源点到终点的最佳路径（确定路由表）；
  * 使用两个出口地址（下一跳网络地址和出口物理地址）建立转发表。

**路由信息的来源**
* Neigghbor/Peer
* Announce/Accept
* Originate

**路由测度**

通路长度、可信度、时延、带宽、负载

**路由算法的基本要求**
* 优化路径选择
* 开销小
* 快速收敛
* 可扩展性好
* 易配置
* 支持策略路由
* 可靠性和鲁棒性
* 传输服务支持（QoS、多路径（解决传输性能问题））

## 距离向量协议（Bellman-Ford协议）

**路由扩散方式**

根据距离向量协议，它要求网内各个节点向自己所有的邻节点广播它对网内其他节点的可达性（用距离来衡量），并通过逐级扩散的方式使这种可达性信息在网内传播，从而使各个节点能推算出自己到网内其他非邻接节点的路由。

**最短路径原则**

各节点根据最短路径原则（即跳数最少）选择自己到网内其他节点的路由。

**收敛过程**

网络刚启动时，各个节点的路由表为空，需要经过一段时间的广播扩散，才能建立各节点的路由表。在收敛期间，一些节点的路由表不完备，因为有一些路由尚未广播到，这时网络不能正常工作。路由表的收敛速度与路由的广播频度有关，同样与网络的传输开销也有关。

**路由不对称性**

由于各节点是自发进行广播的，路由表的建立有一定的随机性，取决于收到广播的次序。若网络中两个节点之间存在两条距离相同的路由，则双方的选择可能会不一样，因此它们之间的路由可能是非对称的。

**路由表的维护**

* 在距离向量协议中，每个节点在收到邻节点的广播信息之后，要与自己路由表的内容进行比较。对于路由表中的每一条路由：
  * 若该路由信息是来自于这个邻节点，则若该路由的距离变化了，要按新的距离修改原来的路由；
  * 若该路由信息不是来自这个邻节点，若路由表中没有该点信息，或收到的节点距离小于原有距离，于是将该距离+1，记入路由表。
* 当网络发送故障使某条链路中断时，这个链路两端所连接的两个节点要经由该链路的路由距离设置为无穷大，然后广播这个故障信息，逐渐收敛到新路由。
* RIP的定期广播会在网络中产生同步效应，即在网络中产生周期性的流量高峰，因为大家的时钟基本一致，广播周期相同。解决方法：随机设置广播间隔（15S - 45S）。

**慢收敛问题的解决**

* 水平分割
* 触发更新
* 毒性逆转
* 抑制机制

## BGP

边界网关协议（BGP）是运行于 TCP 上的一种自治系统的路由协议。BGP 是唯一一个用来处理像因特网大小的网络的协议，也是唯一能够妥善处理好不相关路由域间的多路连接的协议。 BGP 构建在 EGP 的经验之上。 BGP 系统的主要功能是和其他的 BGP 系统交换网络可达信息。网络可达信息包括列出的自治系统（AS）的信息。这些信息有效地构造了 AS 互联的拓朴图并由此清除了路由环路，同时在 AS 级别上可实施策略决策。

BGP 跟 IGP 不一样，它并不能自己构建路由表，它只是传播路由：我不生产路由，我只是路由的搬运工。

* AS的边界路由器称为BGP路由器，要求相邻AS中的两个 BGP路由器必须处于同一个物理网中。
* BGP向邻接点通告路由信息
  * 基于逐跳的路由模型
  * 基于路由策略
  * BGP不对路由表进行定期刷新

BGP的邻居关系（或称通信对端/对等实体）是通过人工配置实现的，对等实体之间通过TCP(端口179)会话交互数据。BGP路由器会周期地发送19字节的保持存活keep-alive消息来维护连接（默认周期为30秒）。在路由协议中，只有BGP使用TCP作为传输层协议。

同一个自治系统(AS)中的两个或多个对等实体之间运行的BGP 被称为 IBGP(Internal/Interior BGP)。归属不同的AS的对等实体之间运行的BGP称为EBGP (External/Exterior BGP)。在AS边界上与其他AS交换信息的路由器被称作边界路由器(border/edge router)。在互联网操作系统（Cisco IOS）中，IBGP通告的路由的距离为200，优先级比EBGP和任何内部网关协议（IGP）通告的路由都低。其他的路由器实现中，优先级顺序也是EBGP高于IGP，而IGP又高于IBGP。

### BGP的关系

* Peering关系指两个AS之间协商仅在它们以及他们的客户AS之间交换流量，也就是相互通告相应的路由，以改善相互间的可达性以及健硕性，并减少向上游的转送成本。（例如CERNET与国内各大运营商的互联）
  * Peering是一个非传递关系，它的好处是网络延迟更低，对路由的控制能力更强，丢包率更低
* Transit 是客户和供应者AS之间的商业关系
  * 供应者AS答应通告客户AS的路由使得客户AS可以被外界所访问；
  * 客户AS使用供应者AS提供的Internet路由或者是将供应者AS作为默认的路由，以访问Internet；
  * 客户AS需要为这些服务（可达性和访问）向供应者AS付费。
  * 例如企业网与运营商的互联



### 初始交换规程

* BGP使用TCP作为传输协议.
* BGP在TCP建立之后，双方均要发送 open报文，以协商连接的参数。
* 如果两个BGP路由器同时发起连接建立的要求，则会发生冲突，这时使用BGP连接标识符值大(即地址大的)的一方所发起建立的连接；另一方发起的建立若以完成，将其拆除，否则丢弃。
* 如果同意，用keepalive应答；否则notification应答，给出原因。

**BGP UPDATE Message**

当BGP连接建立之后，BGP路由器就开始使用UPDATE报文进行路由更新信息的交换（给出每个通路向量对应的路由）

### BGP协议工作状态

1. Idle：BGP协议初始时是处于Idle状态。在这个状态时，系统不分配任何资源，也拒绝所有进入的BGP连接。只有收到Start Event时，才分配BGP资源，启动ConnectRetry计时器， 启动对其它BGP对等体的传输层连接，同时也侦听是否有来自其它对等体的连接请求。
2. Connect：这个状态下，BGP等待TCP完成连接。若连接成功，本地清空ConnectRetry计时器，并向对等体发送OPEN报文，然后状态改变为OpenSent状态；否则，本地重置ConnectRetry计时器，侦听是否有对等体启动连接， 并移至Active状态。
3. Active：这个状态下，BGP初始化TCP连接来获得一个对等体。如果连接成功，本地清空ConnectRetry计时器，并向对等体发送OPEN报文，并转至OpenSent状态。
4. OpenSent：这个状态下，BGP等待对等体的OPEN报文。收到报文后对报文进行检查，如果发现错误， 本地发送NOTIFICATION报文给对等体，并改变状态为IDLE。如果报文正确，BGP发送KEEPALIVE报文，并转至OpenConfirm状态。
5. OpenConfirm：这个状态下，BGP等待KEEPALIVE或NOTIFICATION报文。如果收到KEEPALIVE报文，则进入Established状态，如果收到NOTIFICATION报文，则变为Idle状态。
6. Established：这个状态下，BGP可以和其他对等体交换UPDATE，NOTIFICATION， KEEPALIVE报文。如果收到了正确的UPDATE或KEEPALIVE报文，就认为对端处于正常运行状态，本地重置Hold Timer。如果收到NOTIFICATION报文，本地转到Idle状态。如果收到错误的UPDATE报文，本地发送NOTIFICATION报文通知对端，并改变本地状态为Idle。 如果收到了TCP拆链通知，本地关闭BGP连接，并回到Idle状态。

![bgp-machine](bgp-machine.png)

bgp是基于tcp协议的，即包含了tcp协议的优点，因此上面的状态机也就跟tcp连接有一定的关系：
* tcp连接建立阶段的状态：Idle， Connect， Active
* tcp连接建立完成之后： OpenSent， OpenConfirm， Established

### BGP的策略

* BGP通过根据多个备选方案的属性和本地需求从多个备选方案中选择路径，并控制对其他AS的广播来实施策略。
* 策略不是BGP的一部分：它们是作为配置信息提供给BGP的。
  * 策略路由：依据报文分类决定转发方向
  * 路由策略：控制路由信息传播

### BGP的路由选择模型

BGP协议存在自己的路由表，与路由器正在使用的IP路由表不同，后者是供IGP使用的。

### Routing Information Bases (RIB)

* 路由信息存放在RIBs中
* RIB-In：从其他路由器学习的路由信息（未处理的路由信息）
* Loc-RIB：从邻近-RIB-In中选择的本地路由信息（本地选择的路由）
* RIB-Out：广播要向同行宣传（广播宣传路线）

通信世界里，有很多地方涉及到 peer 这个概念（比如 MPLS LDP peer），有的对等体是自动发现的，而有些是人工指定的。如果组成 BGP peer 的两个路由器，分属两个 AS，那么这样的 BGP 就称作 EBGP；如果两个路由器，同属一个 AS，那么这样的 BGP 就称作 IBGP。

### I-BGP（内部BGP）

对同一个自治域内所有边界路由器作状态表项

* 在同一AS内的BGP路由器之间使用
* IBGP路由器之间不通告间接获得的路由信息，因此AS内所有的IBGP路由器之间都必须相互建立相邻关系。
* BGP必须与域内的IGP同步，必须等IGP作出路由更新之后再向外进行路由通告。（内部BR的路由表必须先同步）

### EBGP（外部BGP）

用于在不同的自治系统间交换路由信息。

**EBGP与IBGP的区别**

1. 路由环路的避免措施不一样，IBGP强制规定ibgp speaker不允许把从一个IBGP邻居学习到的前缀传递给其它IBGP邻居，因此IBGP要求逻辑全连接。EBGP没有这样的要求，EBGP对路由环路的避免是通过AS_PATH属性来实现的。
2. 使用的BGP属性不同，例如IBGP可以传递LOCAL_PREF（本地优先属性），而EBGP不行。
3. IBGP有同步的要求，而EBGP没有同步的要求
4. IBGP不需要IBGP邻居之间有物理连接，只需要逻辑连接即可，而EBGP下一般情况下都要求EBGP邻居之间存在物理连接。

### 路径属性的类别

公认必遵、公认自决、可选过渡、可选非过渡

### Path Vectors

从源点到宿点所经历的AS序列，生成或更新时要检测路由回路

### MED

当针对某个前缀的两个或多个路由的局部偏好和AS路径长度相同时，MED属性就会发挥作用。MED通常用于提供者/订阅者的场景。如果在ISP之间使用，可能会导致不公平，因为它可能迫使一个ISP承载更多的流量。

### 缺省路由

* 在BGP中缺省路由的通告为0/0，提供这个路由，表示愿意作为对方的缺省路由出口。（上用下不用）
* 可以为缺省路由设置local-pref参数值，从而确定主用和备用的缺省路由出口。
* BGP中可以静态指定缺省路由（下个BGP路由器的IP地址、一个特定路由器的接口、一个网络地址）

### Two Links to the Same ISP

两条链路上通告的IP地址如果相同，则构成主备关系；如果不同则构成分流关系。

## Multi-Home

**单归路连接**

* 用户与ISP之间只有一条链路连接
* Provider/Customer或Peer/Peer关系
* Stub Network

**Multihoming（多宿主）**

* 连接到同一个ISP的两条或多条链路
* 连接到不同ISP的两条或多条链路

**多归路路由：Multi-homing**

* 路由的冗余度可以为流量提供多个迂回路由，这要求与一个或多个AS建立多条连接。
* 对称性
* 负载均衡主要是靠对路由使用的来实现的，选择向外通告的路由还影响入流量，而来自外部的路由更新会影响出流量

**Multi-Homed Stub Network**

使用BGP进行负载均衡、要求使用私有ASN、上行AS需要向外通告这个网络的地址，使其从外部可达、访问能力受上行AS的限制

有多种应用的可能，例如：在同一个ISP中的分流、作为备份链路、进行负载均衡、有选择地使用不同ISP的服务、Multihoming增加路由表的规模

### Private-AS的应用场景

用户在自己的主干网中实现多归路接入、一个企业网通过ISP的主干网实现分布在多个地区的子网互联、实现BGP联邦

## PA & PI

* PA地址空间：指的是一段由区域互联网注册管理机构分配给互联网服务提供商的IP地址（比如IANA分配给电信运营商的IP地址）
* PI地址空间：由区域Internet注册中心(RIR)直接分配给最终用户组织的一组IP地址。

* PA地址方式的多归路：网络A从ISP1得到IP地址，并同时与ISP1和ISP2互联以构成多归路。
* PI地址方式的多归路：网络A从ISP3获得IP地址，并与ISP1和ISP2构成多归路。

PA和PI的最大区别是能否聚类：PA可以，PI不可以。

## 路由反射

**问题**

AS内所有的BGP路由器之间需要手工建立两两的对等相邻关系，称为BGP路由器的全闭合网。（I-BGP路由器是不能转发路由信息）

IBGP路由传递原则可以认为只传一跳，在实际的网络中，设备非常多，网络联接非常复杂，不太可能每个AS内的设备都有邻居关系，但路由又必须传递下去。为了解决这一麻烦，推出了路由反射器技术，可以大量减化设备配置，也可以减少邻居条目，还可以减轻设备CPU负担，在实际网络环境中被大量使用，因为反射器配置非常简单。

**定义**

利用路由反射可以解决这一问题。在一个AS内，其中一台路由器作为路由反射器RR(Route Reflector)，其它路由器做为客户机(Client)。客户机与路由反射器之间建立IBGP连接。路由反射器和它的客户机组成一个集群(Cluster)。路由反射器在客户机之间传递(反射)路由信息，而客户机之间不需要建立BGP连接。

**路由反射器在收到路由更新信息后作如下处理**

* 如果路由从非客户机收到，仅反射给客户机；
* 如果路由从客户机收到，要反射给其他客户机和所有的有相邻对等关系的非客户机；（使用水平分割以防止循环路由）
* 如果路由是从EBGP对等节点收到，要反射给所有的客户机和非客户机对等节点。（从别的群来的发送给自己群内的节点）
* RR的一个好处就是配置方便，因为只需要在反射器上配置，客户机不需要知道自己是客户机。

**BGP路由更新中增加两个属性**

Originator_ID属性和Cluster_List属性，用于检测和防止路由环路：

* Originator_ID属性保证路由在反射器和客户机/非客户机之间的不出现循环。
* Cluster_List由一系列的Cluster_ID组成，描述了一条路由所经过的反射器路径，这和描述路由经过的As路径的AS_Path属性有相似之处。

### 域间路由控制

* 通过协议或网管获得AS的拓扑结构与路由器配置
* 通过测量或SLA定义获得需求矩阵
* 路由控制根据优化目标计算需调整的参数

### 完全自私的结构

* RR实现流量需求统计、路由优化控制和参数设置功能
* 边界路由器Ri与RR之间使用iBGP交换信息和进行配置控制
* 优化只根据本域的目标，只适合Stub类型的AS

## OSPF

OSPF（Open Shortest Path First）：基于Dijkstra的最短路径算法，它是一种基于链路状态的路由协议，它要求各节点发送自己的链路状态(LSA)到同一层次区域(area)的所有其他节点。LSA包括各节点的邻接情况，所使用的测度值等，这样区域内各节点便可同步了解全区域的拓扑情况，并以此来计算到区域内各节点的最短路径（使用IP报文承载OSPF协议路由信息）。

OSPF是一个内部网关协议(Interior Gateway Protocol，简称IGP），用于在单一自治系统（autonomous system,AS）内决策路由。是对链路状态路由协议的一种实现，隶属内部网关协议（IGP），故运作于自治系统内部。

链路是路由器接口的另一种说法，因此OSPF也称为接口状态路由协议。OSPF通过路由器之间通告网络接口的状态来建立链路状态数据库，生成最短路径树，每个OSPF路由器使用这些最短路径构造路由表。

**层次化OSPF**

由一组IP子网构成一个区域，所有区域通过主干网互联，形成逻辑拓扑。
工作机制：区内路由器向ABR报告路由，ABR从/向主干网广播路由摘要，BR从/向AS通告路由摘要

**虚拟连接**

逻辑上要求所有区域必须与区域0直连；虚拟链接的两个端点是区域边界路由器。

**OSPF的路由类型**

域内路由、域间路由、外部路由

**OSPF vs RIP**

* 收敛性：区内各节点的链路信息是广播的，收敛速度快。节点收到所有节点的广播后才开始计算，原则上不会出现路由回路。
* 多测度：允许使用多种路由测度。
* 多通路：支持分流传输，不同实现的分流能力会不一样。
* 支持外部路由：存在专门的边界链路状态记录，支持外部路由的穿越。
* 支持分层结构。

**链路状态数据库**

一个区域内的OSPF路由器共享同一个链路状态数据库，其描述了区域内的网络拓扑，可用以计算最短路径。

**Advertising router**

是负责广播某状态记录的路由器，用它的IP地址标识，若该路由器具有多个IP地址，则选择其中之一作为它的OSPF标识符。

### OSPF协议

支持OSPF路由器之间的交互，它直接运行于IP协议之上，由Hello、交换(exchange)、和广播(flooding)等三个规程组成。
* Hello规程：发现新链路并检查现有链路是否还在正常工作。
* 交换规程：两个路由器在建立了相邻关系后要交换彼此的链路状态数据库，检查并更新数据库、具体路由的交换。
* 广播规程：当链路状态发生变化，负责该链路的路由器要将新的状态广播给其他路由器，同样当收到链路状态请求报文时，对应的路由器也要将这个链路的状态记录传给询问者。

OSPF路由协议是一种典型的链路状态（Link-state）的路由协议，一般用于同一个路由域内。在这里，路由域是指一个自治系统（Autonomous System），即AS，它是指一组通过统一的路由政策或路由协议互相交换路由信息的网络。在这个AS中，所有的OSPF路由器都维护一个相同的描述这个AS结构的数据库，该数据库中存放的是路由域中相应链路的状态信息，OSPF路由器正是通过这个数据库计算出其OSPF路由表的。

作为一种链路状态的路由协议，OSPF将链路状态组播数据LSA（Link State Advertisement）传送给在某一区域内的所有路由器，这一点与距离矢量路由协议不同。运行距离矢量路由协议的路由器是将部分或全部的路由表传递给与其相邻的路由器。

链路状态（LSA）就是OSPF接口上的描述信息，例如接口上的IP地址，子网掩码，网络类型，Cost值等等，OSPF路由器之间交换的并不是路由表，而是链路状态（LSA），OSPF通过获得网络中所有的链路状态信息，从而计算出到达每个目标精确的网络路径。OSPF路由器会将自己所有的链路状态毫不保留地全部发给邻居，邻居将收到的链路状态全部放入链路状态数据库（Link-State Database），邻居再发给自己的所有邻居，并且在传递过程中，绝对不会有任何更改。通过这样的过程，最终，网络中所有的OSPF路由器都拥有网络中所有的链路状态，并且所有路由器的链路状态应该能描绘出相同的网络拓朴。

**OSPF特征总结**

* 基于真实度量的最短路径路由，不仅仅是跳数
* 允许跨相等路径的路由，执行负载均衡
* 支持服务类型(TOS)路由
* 允许注入外部路由（来自其他自治系统的路由）
* 认证路线交换
* 快速收敛

**目前存在的问题**

基于目的地址的转发机制，不能基于每个源端的需求、不能动态满足源对特定应用的带宽和时延需求、所有的信令是逐跳产生和传递的、在任一链路拥塞时，不能自动地调控流量路径、要提供带宽保证、不能分辨应用于网络流量行为的联系。

**解决方法**

SDN+段路由（一种替代LDP和RSVP协议实现标记分配的方法）

## MANET

**移动Ad hoc网络/多跳无线网络**

传统的无线蜂窝通信网络，需要固定的网络设备如基地站的支持，进行数据的转发和用户服务控制。而无线自组织网络不需要固定设备支持，各节点即用户终端自行组网，通信时，由其他用户节点进行数据的转发。这种网络形式突破了传统无线蜂窝网络的地理局限性，能够更加快速、便捷、高效地部署，适合于一些紧急场合的通信需要，如战场的单兵通信系统。但无线自组织网络也存在网络带宽受限、对实时性业务支持较差、安全性不高的弊端。国内外有大量研究人员进行此项目研究。

无线自组织网络(mobile ad-hoc network)是一个由几十到上百个节点组成的、采用无线通信方式的、动态组网的多跳的移动性对等网络。其目的是通过动态路由和移动管理技术传输具有服务质量要求的多媒体信息流。通常节点具有持续的能量供给。它的特点如下：

* 是一个多跳、临时、无中心网络，不需要现有信息基础网络设施的支持，可以在任何时候、任何地点快速构建（自组网）
* 网络中每个终端都带有无线通信收发装置可以自由移动、低位相等（对等网）
* 有限的无线传输带宽，且存在单向的无线信道
* 生存时间短，安全性差，网络的可扩展性不强

**MANET关键问题**

路由协议、服务质量、功率控制、安全问题、节点移动、隐藏节点、信息不齐

**MANET路由的基本方法**

* 根据决策时间
* 根据网络结构

## LSR

LSR 为基于链路状态的路由算法。如何判断链路状态呢？在无线通信的环境下，只需要节点能够收到另一节点的包，就说明链路有效。另一方面，为了建立端到端的路径，路由算法需要发现并检查一跳由多个单跳链接组成的多条链路的可用性，这就需要不断的洪泛广播(flooding)来进行。这种洪泛的方式是非常浪费的。为了在网络中同步节点状态，需要各个节点进行洪泛广播，产生大量冗余的通信，在能源受限的移动网络中是非常不经济的。OLSR 通过有选择的洪泛转发(MPR: Multi-Point Relay)来解决这个问题。

### OLSR（针对Ad Hoc需求的经典链路状态算法的优化协议）

* 基于链路状态算法的逐跳Proactive(table-driven)路由协议-路由基于维护在中间节点的动态路由表项
* 节点仅向处于其multipoint relay selector set的邻接点通告状态信息，同时只通过multipoion relay节点在网络中发送数据。
* 完整进行路由更新，并使用顺序号来维持数据的完整性，因此不需要可靠传输的支持

**拓扑管理**

OLSR有两种控制分组：Hello分组和TC分组（Tologogy Control)
* HELLO 用于建立一个节点的邻居表：邻居节点的地址，本节点到邻居节点的延迟或开销（延迟就是指时间）
  * OLSR 采用周期性地广播 HELLO 分组来侦听邻居节点的状态，包括他们的链路状态。HELLO 分组只在一跳的范围内广播，不能被转发。
  * Hello分组的作用只是为了看链路状态，选择MPR
* TC分组全网广播（MPR一定要被转发）
  * TC信息中包含“MPR的邻居节点”都将收到"我的TC分组"，但收到就收到，只有MPR才能转发。
  * TC分组作用计算出网络的拓扑图

### Multipoint Relays（多中继依赖节点）

网络中每个节点N都选择一组邻近节点MPR(N)作为其multipoint relays，用于转发来自N的控制报文，节点在从自己的一跳邻居节点中选择 MPR 时：
* 必须选择和自己之间存在双向对称链路的节点。
* 节点所发送的分组通过 MPR 的中继，能够到达所有的两跳邻居节点,目的是为了——方便确认数据分组有没有被下个节点成功接收，这就是常说的“反馈”。

**邻节点探测**

以 A 和 B 两个节点举例，想要检测它们之间链路的状态，需要进行以下几步：
* A 向 B 发送空的 HELLO 消息。
* B 接收到消息后，由于没有在消息中找到 B 自己的地址，所以将 A 设为非对称邻节点。2秒后，B 向 A 发送携带 A 地址的 HELLO 消息。
* A 接收到消息后，在消息中找到了自己的地址，所以将 B 定义为对称链路，接着再向 B 发送带有 B 地址的 HELLO 消息。
* B 收到最新消息后，将 A 视为对称邻节点。

基于这个机制，OLSR 中的节点可以进行邻节点的探测，如果与某个邻节点的连接状态变为双向对称连接，则记录在 neighbor set 中，并开放接口连接邻节点；如果连接状态建立失败，则删除记录。而通过 HELLO 消息广播过程，可以让网络中所有节点都能知晓距离自己两跳及以内的邻居的信息。

**MPR 的选择**

基于上述过程建立的邻居信息表，节点可以选择出邻居 MPR 节点集合。一个节点选定的 MPR 是负责转发此节点的广播消息的节点，通过控制 MPR 集合的大小可以减少洪泛的开销。主要分为两步：
* 首先选择能够覆盖孤立两跳邻节点的一跳邻节点。这里的孤立两跳邻节点是指仅通过一个邻节点同目标节点相连的两跳邻节点。
* 在余下的一跳邻节点中，按照覆盖二跳邻节点的数量从高到低依次选择，直到覆盖所有的两跳邻节点。

**MPR作用**

每个节点在自己的一跳邻居节点之中选择一部分节点作为多点中继站，只有被选为 MPR 的邻居节点才负责转发控制消息，节点之间周期性地交换各种控制信息（只有被选择为MPR的才能发控制消息），通过分布式计算来更新和建立自己的网络拓扑图。被选为 MPR 的节点则通过发送控制消息周期性地向全网声明通过自己可以到达自己的 MPR Selector。

## Autonomous System（自治系统）

* 自治系统AS：单一技术管理下的一组路由器，用唯一分配的AS号标识
* AS可以独立地决定网络的互联关系，以便更有效地进行路由选择\
* 管理域控制了路由的扩散，因此产生外部路由的概念
* 外部信息是可达性的路由信息，而内部路由是可操作的路由信息（例如根据测度选择最优通路等）
* AS内部使用域内路由协议（IGP），AS之间的路由使用域间路由协议（EGP）。

**两种关系**

* Transit：是客户和供应者AS之间的商业关系（是要钱的，但是可以通过对方网络来访问别的网络）。
* Peering：Peering关系指两个AS之间协商仅在它们以及他们的客户AS之间交换流量，也就是相互通告相应的路由，以改善相互间的可达性以及健硕性，并减少向上游的转送成本（相互开放对方的用户，双方属于互利关系，互相不收钱，但是只能发给目标是对方网络或者对方客户）。

**AS之间的连接关系**

* 效益最大化 vs. 收益最大化
* Customer-Provider
* Sibling-Sibling
* Backup Sibling
* Indirect Peer
* ISP希望寻求有利于自己的互联方式（Valley-free原则）

## POP

**Point-Of-Presence（POP）**

ISP的外边界点称为POP。ISP的POP覆盖范围确定它的规模，如全国性网络或区域性网络。分为接入点和互联点。

**接入点的实现结构**

* 通过高密度的接入设备实现端系统的汇聚
* 提供接入网与主干网之间的边界控制
* 通常采用多机备份结构（通常设置VLAN来实现、容错、策略路由）

**互联点的实现结构**

* 基于L2的IXP结构（参加互联的各路由器之间存在一个全互联的拓扑结构）
* 基于L3的IXP结构（采用路由仲裁者（RA）作为中央处理器）

## VPN

**VPN的用途**

代理服务器Proxy Server，其功能就是代理网络用户去取得网络信息。形象的说：它是网络信息的中转站。与代理服务器不同。VPN是解决通过外网访问内网资源的一种远程连接方式，如下面的情况：

* 公司出差员工，可以通过vpn登陆公司内网进行办公；(远程接入VPN)
* 各个分公司可以通过vpn与总公司联系；（内联网VPN）

**什么是VPN**

VPN就是利用开放的公众IP/MPLS网络建立专用数据传输通道，将远程的分支机构、移动办公人员等连接起来。

* V(Virtual): 虚拟通道，不需要专用线路。
* P(Private): 安全的，数据进行加密传输
* N(Network): 远程连接

VPN虚拟专用网，通过对传输的数据进行加密，在公网上实现了一条虚拟的所谓专用线路进行安全传输。所以，如果需要在公网或者外网访问内网的资源或者电脑，那就可以在内网建立VPN，这样就方便多了。

**逻辑专网**

VPN是使用IP设施对专用广域网（WAN）设施的仿真。

**VPN的类型**

* 根据网络功能分类：
  * L3VPN
  * L2VPN
  * AccessVPN
* 根据管理责任分类：
  * 用户端管理的VPN
  * 服务端管理的VPN（PPVPN）
* 设备位置分类：
  * VPN设备在用户端
  * VPN设备在服务提供者端

### IP-in-IP封装（IP 隧道：IP tunneling）

* 将要传送的IP报文封装在另一个IP报文
* 外层报头的源宿地址分别是隧道的起点和终点
* TTL要足够大，以穿越隧道
* 封装前要检查由是否存在路由回路

### 最小封装

* 通过去掉封装报文中内层IP报头和外层IP报头中的冗余部分来减少隧道的额外开销。
* 由于分段字段被压缩掉了，因此被封装的IP报文不能分段。

### Generic Routing Encapsulation（GRE）

通用路由封装协议GRE（Generic Routing Encapsulation）：实现任意一种网络协议在另一种网络协议上的封装，主要用于用IP报文封装任意一种其它报文；IP-in-IP和GRE都是属于IP隧道技术，GRE主要用于实现专线VPN业务。

### L2VPN & L3VPN & MPLS

L3VPN是为了将私网和公网进行对接，就好比将一个个的私人空间与公共空间对接，同时也能从公共空间获取对个人有用的资源。

私网VPN1和VPN2分别通过公共网络实现相互通信。这两个VPN私网可以使用相同的IP地址，那么如何区分呢？答案就是采用VRF实现不同VPN之间的路由隔离。且每个VRF在PE上都会有相对独立的路由表和标签转发表（根据这两个转发表，实现在公共网络内不同VPN业务按照各自的最优路由达到目的地）。

* L3VPN可以当作是一个超级路由器，一般作为国干网的核心，起到连接各个大区节点的作用；
* L2VPN可以理解为一个超级交换机，一般是省市城域网里面用；

#### MPLS L2VPN

![l2vpn](l2vpn.png)

简单来说，MPLS L2VPN就是在MPLS网络上透明传输用户二层数据。相对于MPLS L3VPN，MPLS L2VPN具有以下优点：

* 可扩展性强：MPLS L2VPN只建立二层连接关系，不引入和管理用户的路由信息。这大大减轻了PE（Provider Edge，服务提供商边缘设备）甚至整个SP（Service Provider，服务提供商）网络的负担，使服务提供商能支持更多的VPN和接入更多的用户。
* 可靠性和私网路由的安全性得到保证：由于不引入用户的路由信息，MPLS L2VPN不能获得和处理用户路由，保证了用户VPN路由的安全。
* 支持多种网络层协议：包括IP、IPX、SNA等。

#### 基于MPLS的以太网

支持两种传输模式（以太网VLAN模式、以太网端口）

#### L3VPN

![l3vpn](l3vpn.png)

* VPN的各个节点分布在不同的MPLS网络中
* VPN的路由信息如何在不同的AS之间发布
  * 方案1：VRF直连
  * 方案2：使用直接相邻的MP-BGP发布VPN路由
  * 方案3：基于RR的多条MP-BGP路由发布

* 方案1：使用连续的VRFs来连接ASBRs；VRF需要在路由器中显式地创建，每个VPN一个；ASBR之间不使用MPLS，但是不同的VPN配置使用不同的路由表（VRF）。
* 方案2
  * （控制平面）：PE把所有的VPN路由通告给ASBR；ASBR将所有VPNv4保存在BGP路由表中，并在转发前重写下一跳和标签字段；ASBR没有VRF表，除非它同时也是PE；
  * （数据平面）：L1、L2和L3均为BGP VPN标号；隧道标号（基于IGP路由）未显示。
* 方案3
  * （控制平面）：不同的AS之间使用RR（路由反射器）交换VPN路由；ASBR要对隧道标号重分配，所以LSP是不跨域的。
  * （数据平面）：使用三层MPLS标记：最内层标记L1标识VPN的网段；中间层标记（L2、L3）VPN的节点；最外层标记PE1和PE2之间的正常MPLS网络LSP。

#### 各种情况下报文结构

![mpls](mpls.png)

### VPWS（Virtual Private Wire Service）流量封装

VPWS提供点到点的二层数据链路帧传送业务。运营商网络边缘路由器(PE)和运营商网络内部的路由器(P)都是由运营商来维护管理的路由器，用户边缘设备(CE)通过以太网、ATM或FR等二层链路接入系统。

**VPWS基本参考模型**

* CE是用户侧的接入设备，负责将用户业务流通过直连电路(AC)发往PE；
* PE路由器上要支持L2VPN协议规程，包括在控制面上通过信令建立PE到PE的伪线路连接，数据面上完成二层数据链路帧到IP/MPLS标记包的封装/去封装和相应处理功能，并通过PSN隧道中的伪线路将标记包传送到对端PE；
* P路由器支持L2VPN业务流的透明传送，不支持L2VPN规程，只起提供承载通道的作用，PE之间建立的包交换(PSN)隧道可以经过多个P路由器；
* 直连电路(AC)是指用户接入L2VPN系统所使用的ATM虚电路、FR虚电路或以太网VLAN链路；
* 伪线路(PW)是指PE之间利用L2VPN信令建立的连接，PE将AC传来的二层数据帧通过PW传送到对端PE，对端PE再恢复或重新生成二层链路帧传送到对端AC；
* 包交换(PSN)隧道是指IP/MPLS网络上的MPLS LSP(标记交换路径)或L2TP隧道，多条PW可以复用在一条PSN隧道中从PE传往对端PE。

可以看出，VPWS可以充分利用IP/MPLS网络资源来支持点到点的数据业务，但是骨干网内PE到PE的信令会话数量和PSN隧道数量可能会引发扩展性问题。为了解决这个问题，引入了伪线路转节点(S-PE)的概念，PE设备分别与S-PE建立伪线路连接，PE到PE的端到端的连接变成了经过一个或多个S-PE转接的连接，通过S-PE的转接减少PE之间端到端网状连接的数量。

**特点**

* 利用隧道标签在PE之间交换数据包
* VC标签标识PW
* 在PEs之间标记VC label
* LSP隧道提供了隧道标记（Tunnel label）
* 可选控制字（CW）携带L2控制位并启用排序

![vpws](vpws.png)

* CE路由器的处理：接入链路AC (CE与PE的连接)的报文封装方式由用户的接入方式决定,包括VLAN接入和Ethernet接入。如果是VLAN接入, CE发送到PE的以太网帧头带有一个VLAN TAG,是ISP (Internet Service Provider)为了区分用户而要求打上的服务定界符,称为P-TAG。如果是Ethernet接入, CE发送到PE的以太网帧头中不带PTAG,如果此时帧头中有VLAN TAG,则它只是用户报文的内部标识,称为U-TAG, U-TAG是该报文在发送到CE前已经携带,而不是CE打上的,用于CE区分该报文的VLAN,对于PE设备没有意义。
* PE路由器的处理：当二层透传的端口有数据包进入PE路由器时, PE路由器通过匹配VCID找到与之对应的隧道标记和虚拟链路标记, PE路由器会将此数据包打上两层标记,其中外层标记为隧道标记,指示从该PE路由器到目的PE路由器的路径,内层标记为虚拟链路标记,指示在该目的PE路由器上属于哪个VCID对应的路由器端口。PE路由器要监视各自端口上的二层协议状态,当出现故障时,通过标记分发协议进程来取消虚拟链路标记,从而断开二层透传,避免产生单向无用数据流。

CE1发送经过二层封装的报文到PE1, PE1查对应的Virtual SwitchInstance(虚拟交换实例)中的表项,为该报文选择隧道和PW, PE1路由器会将此数据包打上两层MPLS标签(外层标记隧道标记和内层标记虚拟链路标记) ,再进行二层封装后转发。PE2路由器收到PE1发送来的报文,对该报文进行解封装,即去掉PE1的二层封装和两层MPLS标签,然后把解封装后原始二层报文发给CE2。

### LDP和BGP不同

采用LDP协议比较简单,对PE要求相对较低, LDP不能提供VPN成员自动发现机制,需要手工配置;采用BGP协议要求PE运行BGP,对PE要求较高,可以提供VPN成员自动发现机制。LDP方式需要在每两个PE之间建立LDP Session,其Session数与PE数的平方成正比;而用BGP方式可以利用RR (Route Reflector)降低BGP连接数。LDP方式分配标签是对每个PE分配一个标签,需要的时候才分配; BGP方式则是分配一个标签块,对标签有一定浪费。LDP方式必须保证所有域中配置的VPLS Instance都使用同一个vSI ID值空间,BGP方式采用VPN Target识别VPN关系。

### VPLS（Virtual Private LAN Service）

是通过分组交换网络PSN连接多个以太网LAN网段，使它们像一个LAN那样工作。

VPLS是一种在WAN范围内仿真LAN业务的技术，主要用于支持以太网业务，对VPWS技术进行了进一步的扩展，在PE之间建立伪线路连接的基础上，增加了对PE设备的功能要求。

支持VPLS的多个PE之间要建立网状连接(也可以借助S-PE建立星状或其他形式连接)，PE收到CE发来的以太网帧后，要根据帧中的MAC地址确定将该帧通过哪条PSN隧道上的伪线路传送到另一个PE，这种转发功能使得整个VPLS系统形式上类似于一个跨越广域网的LAN交换机。

PE上为用户提供了这种LAN交换机的接入接口，使用户使用起来感到非常方便。为了支持这种功能，PE设备除了支持建立伪线路、完成二层链路帧的转发功能外，还要支持MAC地址学习、MAC地址老化处理、桥接转发、广播抑制等二层交换机需要支持的功能。

**VPLS PE的控制平面主要有以下四种功能**

* 成员发现：找到同一VPLS中所有其他PE的过程。这可以通过手工配置的方式实现，也可以通过使用某些协议自动完成。使用协议自动完成的发现方式称为“自动发现”。
* 信令机制：在同一VPLS的PE之间建立、维护和拆除PW的任务是由信令协议完成的。（使用BGP或LDP信令实现VPLS的控制平面的功能）
* 封装：从CE收到的以太网帧后，PE首先对其封装后再发送到分组交换网络上。
* 转发：根据报文是从哪个接口上接收的以及报文的目的MAC地址决定如何转发报文。

**报文转发过程**

![vpls](vpls.png)

以CE1到CE2的VPN1报文流向为例,说明基本数据流走向: 

* CE1上送二层报文,通过AC接入PE1
* PE1收到报文后,由转发器选定转发报文的Pw,系统再根据PW的转发表项压入PW标签,并送到外层隧道(PW标签用于标识Pw,然后穿越隧道到达PE2),经公网隧道到达PE2
* PE2利用Pw标签转发报文到相应的AC,将报文最终送达CE2。

#### 二者对比

* VPWS和VPLS两者都提供了私有的二层VPN服务，不同的是VPWS提供的是第二层的点到点服务，也称为L2VPN。
* 而VPLS提供的是点到多点服务，类似于将骨干网虚拟成一个大的交换机。
* 与VPWS服务类似的还有一种L2TPv3（第二层隧道协议版本3），两者的区别在于承载流量的底层协议不同，VPWS承载在MPLS上，而l2tpv3承载在IP网络中

#### Forwarding

* MAC Address Learning：SP网络可被视为一个网桥
* Aging：转发表FIB的时效控制
* Flooding：PE不转发Flooding帧

## VLAN

**虚拟局域网标签（VLAN Tag）**

用以标识VLAN的相关信息：

* 服务定界：VLAN Tag由服务提供者设置，用来区分不同用户的流量，NSP在将以太帧交给PW终点之前将raw mode剥去。
* 非服务定界：用户自己的VLAN定义

如果两种VLAN Tag同时使用，则服务定界VLAN Tag总在外层。

**P-VLAN与C-VLAN之间的控制信息交互**

* Peer mode（P-VLAN的OAM与C-VLAN的OAM对等交换信息）
* Tunnel mode（C-VLAN的控制信息透明穿越）
* Discard mode（P-VLAN丢弃C-VLAN的控制帧，例如用户的PAUSE帧。）

**Mulit-homing 和 Path Selection**

* CE可同时接入多个PE
* 两个VPLS NLRI相同：Route Distinguisher、VE ID和VBO均相同

## Peer模型

* IP网络的受限互联结构
* CE将自己的路由通告给所附接的PE
* PE仅在同一个VPN的PE之间使用BGP相互通告所了解的路由
* BGP对每个路由都指派一个MPLS标记 (因为可能是私有地址)，也由BGP通告；报文由宿地址对应的MPLS标记标识，然后封装在SP网络的IP隧道中进行传输

## VPN路由转发表

在PE的各个端口定义VPN、在PE中配置所有的CE (用CE-id标识)，特定的RT属性，PE中连接这些CE的物理端口、PE对收到的标记信息要根据其所属的RT来判定它属于哪个VPN

**基本结构**

* 使用VRF（Virtual Routing and Forwarding）来表示VPN customer，需要网管配置
* PE使用IGP向全局路由表提供正常路由
* PE使用VRF-aware路由协议向VRF路由表提供VPN customer路由

## VRF

为了在边缘侧设备上识别不同的VPN信息，提出了VRF的概念。在L3VPN组网中，不同VPN之间的路由通过VRF进行隔离。每个VRF可以看做是一台虚拟的PE设备，管理单独的VPN业务，储存路由信息。每个VRF包含的路由信息有与此VRF相关的直连从客户边缘侧接收到的路由，以及从其他网络侧边缘路由器接收到的具有可接受的BGP属性的路由。

**控制平面处理流程**

* PE1收到一个IPv4路由更新
* PE1将其翻译成为VPNv4地址并以此构造 MP-iBGP UPDATE message
* PE1使用MP-iBGP将这个路由更新发送到其它PE
* PE2接收后检查是否本地有VRF的 import RT被设置成 RT=1:2
* PE2用正常方式将这个IPv4 prefix通告给CE2

**数据平面处理流程**

* PE2 使用两个MPLS标号（外层标号对应PE1的地址，通过LDP分配，内层标号对应VPN地址，通过BGP分配）
* P1 倒数第二跳（PHP）
* PE1从MPLS报文中获得IP报文并转发给CE1

## Segment Routing

**定义**

SR是一种新型的MPLS技术，其中控制平面基于IGP路由协议扩展实现，转发层面基于MPLS转发网络实现，对的segment在转发层面呈现为标签。SR-TE是使用SR作为控制信令的一种新型的MPLS TE隧道技术，控制器负责计算隧道的转发路径，并将与路径严格对应的标签栈下发给转发器，在SR-TE隧道的入节点上，转发器根据标签栈进行转发。

**架构**

SR架构基于源路由。节点（路由器、主机或设备）选择路径，并且引导数据包沿着该路径通过网络，具体实施是在数据报头中插入带顺序的段列表（segment list），以指示收到这些数据包的节点怎么去转发和处理这些数据包。

Segment其实就是MPLS的标签，分为全局段和本地段，类似于公网地址和私网地址：

* 全局（global）Segment：SR域的任一节点都明白该Segment的相关指令。SR域的每个节点的转发表中都安装了该Segment相关指令（到达目的地的最短路径）。在MPLS SR 中：为段路由全局块（SRGB，标签范围）中的全局标签值。
* 本地（local）Segment：只有该Segment的始发节点明白他的相关指令。在MPLS SR 中，为本地分发的标签。

**粘连标记**

相当于将过长路径标签的一部分封装为一个标记，当到达某个节点的时候，再将这个标记转换为之前的标记。

**转发过程**

![segmentrouting](segmentrouting.png)

1. 入节点A：入节点A为数据报文添加标签栈{1003,1006,100}，然后根据栈顶的标签1003匹配链路，找到对应的转发出接口为A->B链路，之后将标签1003弹出。报文携带标签栈{1006,100}，通过A->B链路向下游节点B转发。
2. 中间节点B：中间节点B收到报文后，根据栈顶的标签1006匹配链路，找到对应的转发出接口为B->C链路，之后将标签1006弹出。报文携带标签栈{100}，通过B->C链路向下游节点C转发。
3. 粘连节点C：粘连节点C收到报文后，识别出栈顶的标签100为粘连标签，将粘连标签100交换为与其关联的标签栈{1005,1009,1010}，然后根据新的栈顶的标签1005匹配链路，找到对应的转发出接口为C->D链路，之后将标签1005弹出。报文携带标签栈{1009,1010}，通过C->D链路向下游节点D转发。
4. 中间节点D、E：节点D、E收到报文后，以与中间节点B相同的方式继续转发。直到节点E弹出最后一个标签1010，数据报文转发至节点F。
5. 出节点F：出节点F收到的报文不带标签，通过查找路由表继续转发。

## SONET/SDH

定义了一组在光纤上传输光信号的速率和格式，通常统称为光同步数字传输网，是宽带综合数字网B-ISDN的基础之一。SONET/SDH采用TDM技术，是同步系统，由主时钟控制，精度 $10^{-9}$。两者都用于骨干网传输。是对沿袭应用的准同步数字系列PDH (Plesiochronous Digital Hierarchy)的一次革命。

TDM就是时分复用模式。时分复用是指一种通过不同信道或时隙中的交叉位脉冲，同时在同一个通信媒体上传输多个数字化数据、语音和视频信号等的技术。

SDH是一种物理传输方式、IP网络是一种网络连接模式、IP ON SDH 即是让IP在SDH的网上运行

## PPP协议

(RFC 1661，Point to Point Protocol)定义了点到点链路上传输多协议数据包的标准方法，是正式的Internet标准。PPP协议在OSI 7层位于网络层之下，为了与网络层平滑地连接，PPP协议在规定了基本接口后还要为不同的网络层协议提供相应的封装控制协议(NCP)。再者，在PPP层下面承载业务的传输媒质也各不相同，如ISDN、FR、SDH/SONE等，这就需要PPP协议为它们提供相应的链路控制协议(LCP)。 

PPP协议包括三个基本组成部分: 

* 在单个串行链路上使用多个协议的封装方法。
* 链路(LCP)，用来建立、配置和测试数据链路连接。PPP连接的两端使用LCP来协调连接选项。
* 一种让PPP连接不同网络层协议的网络控制协议(NCP)。

## IP over WDM

基本工作原理是光纤直接与光耦合器相连，耦合器把各波长分开或组合，输入和输出端都用简单的光纤连接器。在发送端，将不同波长的光信号组合（复用）送入一根光纤中传输；在接收端，又将组合光信号分开（解复用）并送入不同的终端。因此，IP over WDM是一个真正的链路层数据网，可以通过指定波长作旁路或直通连接，网络的业务工程可以只在IP层完成。由于使用了指定的波长，结构更灵活，并具有向光交换和全光选路结构转移的可能。

在光纤上直接传输IP数据包需要选择帧格式（即分帧方法），目前主要使用的两种帧格式是SDH帧格式和以太网帧格式（即IP/SDH/WDM和IP/Ethernet/WDM）。IP over WDM的重叠模型和封装。采用SDH帧格式时，报头载有信令和足够的网络管理信息，便于网络管理。但在路由器接口上，针对SDH帧的拆装分割（SAR）处理比较耗时，影响网络吞吐量和性能，且价格也较昂贵。采用吉比特以太网帧格式（即直接在光纤上运行吉比特以太网）是一种经济有效的方法。此种格式下，报头包含的网络状态信息并不多，但由于没有使用造价昂贵的再生设备，成本相对较低。由于使用了异步协议，对抖动和时延并不敏感。同时，由于与主机的帧结构相同，在路由器接口上无需对帧进行拆装分割操作和为了使数据帧同步的比特塞入操作。

## RIP

路由信息协议（Routing Information Protocol，缩写：RIP）是一种使用最广泛的内部网关协议（IGP）。（IGP）是在内部网络上使用的路由协议(在少数情形下,也可以用于连接到因特网的网络)，它可以通过不断的交换信息让路由器动态的适应网络连接的变化，这些信息包括每个路由器可以到达哪些网络，这些网络有多远等。 RIP 是应用层协议，并使用UDP作为传输协议。(RIP是位于网络层的)

虽然RIP仍然经常被使用，但大多数人认为它将会而且正在被诸如OSPF和IS-IS这样的路由协议所取代。当然，我们也看到EIGRP，一种和RIP属于同一基本协议类(距离矢量路由协议,Distance Vector Routing Protocol)但更具适应性的路由协议，也得到了一些使用。

* 什么是RIP？
  * RIP是一种距离矢量路由协议（Distance Vector Routing Protocol）。基本上，距离矢量路由协议基于距离矢量算法根据目的地的远近（远近=经过路由器的数量）来决定最好的路径。
* RIP的作用是什么？
  * RIP让路由器之间互相传递路由信息。路由器通过RIP，能自动知道远程目的地，而不需要网络管理员给每台路由器添加静态路由信息。
* 如何传递路由信息？
  * RIP把自己所有的路由信息，通过Response包泛洪给邻居。
* 如何计算Metric？
  * RIP用“跳数”来计算cost（metric），每经过一台路由器，“跳数”就增加1。RIP会通过“跳数”最小的路径传输数据包。

## 路由和转发

转发是一个节点在本地执行的一个相对简单的过程，即报文从某台设备的一个端口进入而从另一个端口出去。路由选择依赖于网络发展过程中的不断演进的、复杂的分布式算法。最简单的路由选择可以决定报文发送的下一跳主机的地址，复杂的路由协议可以选择一条从主机1和主机2之间经过若干主机的路径。

**转发表和路由表的区别**

1. 转发表中的一行包括从网络号到发出接口的映射和一些MAC信息，而路由表作为建立转发表的前奏，是由路由选择算法建立的一个表，它通常包含从网络号到下一跳的映射。对于单个主机来说，转发表比路由表更详细；
2. 二者建立的目的也不同：构造转发表－目的是为了优化转发分组时查找网络号的过程；优化路由表是为了计算拓扑结构的改变；
3. 实现方式不同：转发表可以由特殊的硬件来实现，而路由表很少这样

## VPN隧道

**第二层隧道协议**

第二层隧道协议将整个数据帧封装在隧道中。主要包括：

* 点到点隧道协议PPTP（Point-to-Point Tunneling Protocol）：由微软、Ascend和3COM等公司支持，在Windows NT 4.0以上版本中提供。该协议支持PPP在IP网络上的隧道封装。PPTP作为呼叫控制和管理协议，使用一种增强的GRE技术为传输的PPP报文提供流量控制和拥塞控制。
* 二层转发协议L2F（Layer 2 Forwarding）：支持对更高级协议链路层的隧道封装，实现拨号服务器和拨号协议连接在物理位置上的分离。
* 二层隧道协议L2TP（Layer 2 Tunneling Protocol）：结合上述两个协议的优点，既可用于拨号VPN业务，也可用于专线VPN业务。

**第三层隧道协议** 

第三层隧道协议构建的隧道内只携带第三层报文，它用公用网来封装和传输三层（网路层）协议（如IP、IPX、AppleTalk等），此时在隧道内传输的只是网路层的分组。

**第二、三层隧道协议的比较** 

第三层隧道与第二层隧道相比，优势在于它的安全性、可扩展性与可靠性。

* 从安全性的角度看，第二层隧道一般终止在用户侧设备上，对用户网的安全及防火墙技术要求很高；而第三层隧道一般终止在ISP网关，通常不会对用户网的安全提出较高要求。
* 从可扩展性的角度看，第二层隧道内封装了整个PPP帧，可能产生传输效率问题；PPP会话贯穿整个隧道并终止在用户侧设备上，导致用户侧网关需要保存大量PPP会话状态与信息，对系统负荷产生较大的影响，也影响到系统的扩展性；此外，由于PPP的LCP及NCP协商对时间敏感，隧道效率降低会造成PPP会话超时等问题。而第三层隧道终止在ISP的网关内，PPP会话终止在NAS处，用户侧网关无需管理和维护每个PPP会话的状态，从而减轻了系统负荷。
* 多数情况下，第二层隧道协议和第三层隧道协议都是独立使用的。如果合理地将这两层协议结合起来，将可能为用户提供更好的安全性和更佳的性能。

## 网络交换

网络交换是指通过一定的设备，如交换机等，将不同的信号或者信号形式转换为对方可识别的信号类型从而达到通信目的的一种交换形式，常见的有:数据交换，线路交换，报文交换，分组交换。

在计算机网络中，按照交换层次的不同，网络交换可以分为物理层交换（如电话网）、链路层交换（二层交换，对MAC地址进行变更）、网络层交换（三层交换，对IP地址进行变更）、传输层交换（四层交换，对端口进行变更，比较少见）和应用层交换（似乎可以理解为Web网关等）。

网络中的数据交换可以分为电路交换，分组交换（数据包交换）、ATM交换、全光交换，标记交换。其中电路交换有预留，且分配一定空间，提供专用的网络资源，提供有保证的服务，应用于电话网；而分组交换无预留，且不分配空间，存在网络资源争用，提供有无保证的服务。分组交换可用于数据报网络和虚电路网络。我们常用的Internet就是数据报网络，单位是Bit,而ATM则用的是虚电路网络，单位是码元。

## 两层和三层交换

* 交换机(第二层):交换机在每个端口提供一个独特的网络段，从而分离了冲突域。
* 路由器(第三层):路由器可分离广播域，并能连接不同的网络。路由器是根据目标网络层的地址(第三层)而不是工作站数据链路层MAC 地址来引导网络信息流。路由器通常基于软件，因此性能比第二层交换机相对迟缓。
* 第三层交换机(第三层):第三层交换机可部署在使用传统路由器局域网的任何地方。第三层交换机中高级的 ASIC 技术可提供远远高于传统路由器的性能，使它们非常适合网络带宽密集的应用。另外，第三层交换机合并了典型路由器中相互分离的桥接(第二层)和路由(第三层)功能。这些技术的结合提供了一个能大大改进扩充能力的更加自然的网络体系结构。

为掌握第三层交换的优点以及如何更加有效地使用第三层交换，首先必须了解可用于网络设计的两种交换方式: 第二层交换、第三层交换(路由)。

交换是从一个接口接收，然后通过另一个接口发出的过程。第二层与第三层交换之间的区别在于用以确定正确输出接口的帧内信息类型：

* 在第二层交换中，帧的交换基于 MAC 地址信息。
* 在第三层交换中，帧的交换基于网络层信息，如 IP 地址。

**第二层交换**

第二层交换是在前面所述的OSI 模型的数据链路层进行。它检查帧，并根据目标 MAC 地址转发帧。如果知道目标地址，第二层交换机会将以太网帧转发到适当的接口。如果第二层交换机不知道将帧发送到何处，它会将该帧广播转发到所有端口，以了解正确的目标地址。第二层交换机利用这种技术来建立和维护一个跟踪帧目标地址的交换表。对于规模较大的网络来说，这种广播转发操作会产生严重的问题，因为所有这些广播的处理会造成性能的大幅度降低。

**第二层交换的优点**

由于第二层交换相对简单，网络管理员可以建立管理简便且能扩展到数百个节点的网络，而不会遇到太多的第二层广播问题。第二层交换机为网络提供了以下优点:

1. 高带宽：第二层交换机通过将专用带宽分配到每一个端口，为各个用户提供优异的性能。每一个交换机端口表示一个不同的网段，因此每个用户可以获得特定数量的带宽。此外，每个专用网段还能与单项业务一起接收广播业务。
2. VLAN：第二层交换机能够将各个端口组合到逻辑工作组(虚拟局域网或 VLAN)。每个 VLAN 组在逻辑上与交换机的其它部分分离，可帮助将第二层广播业务控制在特定的VLAN组。这提供了以下两个主要优点:
  1. 网络设计人员可以利用 VLAN 来建造能避免特大第二层广播域问题的大型第二层网络。
  2. 网络周围的移动、添加和更改更加容易，因为无论物理位置在哪里，用户始终在他们自己的 VLAN 中。

**第三层交换**

第三层交换机或路由器对 VLAN 通信不可缺少。

1. 业务类别优先化：某些第二层交换机上的业务类别 (CoS) 优先化允许网络管理员根据协议、IP 地址和以太网类型等标准给不同类型的局域网业务分配优先权级别。这使网络管理员可以根据协议、应用或用户控制业务流，从而确保更加高效的网络运转。
2. 用户安全：第二层交换机提供了基于用户的稳健安全机质，这种机质基于网络登录 (802.1x) 技术，可防止任何未经认证的用户接入网络。

第三层交换在网络层进行。它检查数据包信息，并根据网络层目标地址转发数据包。与固定的第二层寻址系统不同，第三层地址由网络管理员安装的网络分层确定。IP、IPX 和 AppleTalk 等协议都使用第三层寻址。通过使用第三层寻址系统，网络管理员可以创建地址组(子网)。这些子网可使网络管理员以一个单元(子网)的形式轻松地管理子网成员，从而支持建立一个能够扩展的分层寻址系统。

第三层寻址系统还比第二层系统更加动态。如果用户移动到另一个位置，其终端站会收到一个新的第三层地址，但第二层 MAC 地址保持不变。这类似于某个人从一个城市搬到另一个城市: 邮政地址将会改变，但个人姓名和身份保持不变。因此，第三层路由网络能将逻辑寻址结构连接到物理基础架构，从而提供了一个比第二层网络更加灵活和更加可扩充的分层结构。

**第三层交换的优点**

1. 提高了网络效率：第三层交换机通过允许网络管理员在第二层 VLAN 进行路由业务，确保将第二层广播控制在一个 VLAN 内，降低了业务量负载。
2. 可持续发展：由于 OSI 层模型的分层特点，第三层交换机能够创建更加易于扩展和维护的更大规模的网络。
3. 更加广泛的拓扑选择：基于路由器的网络支持任何拓扑，并能更轻易超过类似第二层交换网络的更大规模和复杂程度。
4. 工作组和服务器安全：第三层设备能根据第三层网络地址创建接入策略，这允许网络管理员控制和阻塞某些 VLAN 到 VLAN 通信，阻塞某些 IP 地址，甚至能防止某些子网访问特定的信息。
5. 更加优异的性能：通过使用先进的 ASIC 技术，第三层交换机可提供远远高于基于软件的传统路由器的性能。比如，每秒 4000 万个数据包对每秒 30 万个数据包。第三层交换机为千兆网络这样的带宽密集型基础架构提供了所需的路由性能。因此，第三层交换机可以部署在网络中许多具有更高战略意义的位置。

## 单播和组播转发

**单播报文的转发机制**

单播其实就是转发，交换机学习和转发的简单过程如下： 

* 当PC1发送数据到本子网的pc2，数据发送至交换机接口
* 如果交换机MAC表里没有PC1的表项，则保存帧里的MAC源地址并与PC1映射
* 然后交换机查看MAC表有没有PC2的MAC地址，如果有则转发数据，如果没有则发送一个ARP广播要求PC2发送MAC地址响应，然后将其存储并转发数据

**组播报文的转发机制**

在组播模型中，IP报文的目的地址字段为组播组地址，组播源向以此目的地址所标识的主机群组传送信息。因此，转发路径上的组播路由器为了将组播报文传送到各个方位的接收站点，往往需要将从一个入接口收到的组播报文转发到多个出接口。与单播模型相比，组播模型的复杂性就在于此：

1. 为了保证组播报文在网络中的传输，必须依靠单播路由表或者单独提供给组播使用的组播路由表来指导转发；
2. 为了处理同一设备在不同接口上收到来自不同对端的相同组播信息，需要对组播报文的入接口进行RPF（Reverse Path Forwarding，逆向路径转发）检查，以决定转发还是丢弃该报文，RPF检查机制是大部分组播路由协议进行组播转发的基础。 

## IPLS

是一种只支持IP的类似LAN业务。IPLS是VPLS功能上的一个子集，这种业务只支持用户的IP业务。把它分开考虑是因为可能会通过不同的机制来提供这种业务，使得它可以在一个可能不能支持VPLS所有功能的硬件平台上运行。除了下面的情况，IPLS很像VPLS：

* 它假定CE设备是主机或者路由器而不是交换机；
* 它假定该业务只携带IP包，支持包含IP信息的数据包，例如ICMP和ARP，不支持不包含IP信息的2层包。

## ASM和SSM

源特定组播（SSM：Source Specific Multicast）是一种区别于传统组播的新的业务模型，它使用组播组地址和组播源地址同时来标识一个组播会话，而不是向传统的组播服务那样只使用组播组地址来标识一个组播会话。SSM保留了传统PIM-SM模式中的主机显示加入组播组的高效性，但是跳过了PIM-SM模式中的共享树和RP （Rendezvous Point，集合点）规程。在传统PIM-SM模式中，共享树和RP规程使用(x，G)组对来表示一个组播会话，其中（G）表示一个特定的IP组播组，而（x）表示发向组播组G的任何一个源。SSM直接建立由(S,G)标识的一个组播最短路径树（SPT：Shortest Path Tree），其中（G）表示一个特定的IP组播组地址，而（S）表示发向组播组G的特定源的IP地址。

SSM 的一个（S,G）对也被称为一个频道(Channel)，以区分传统PIM-SM组播中的任意源组播组（ASM：Any Source Multicast）。由于ASM支持点到多点和多点到多点两种组播业务模式，因此源的发现过程是ASM复杂性的原因。例如在PIM-SM模式中，用户点击浏览器中的组播内容，接收端设备只被通知到组播组的内容，而没有被通知到组播源的信息。而在SSM模式中，用户端将同时接收到组播源和组播组信息。

因此,SSM特别适合于点到多点的组播服务，例如网络娱乐频道、网络新闻频道、网络体育频道等业务，但如果要求多点到多点组播服务则需要ASM模式。

PIM-SSM是对传统PIM协议的扩展，使用SSM，用户能直接从组播源接收组播业务量，PIM－SSM利用PIM-SM的功能，在组播源和客户端之间，产生一个SPT树。但PIM-SSM在产生SPT树时，不需要汇聚点（RP）的帮助。

一个具有SSM功能的网络相对于传统的PIM-SM网路来说，具有非常突出的优越性。网络中不再需要汇聚点，也不再需要共享树或RP的映射，同时网络中也不再需要MSDP协议，以完成RP与RP之间的源发现。

## 物理网络和逻辑网络和节点

把计算机硬件介质“联接”成的网络称为物理网络

目前普遍采用的是传输控制协议网际协议TCP/IP即TCP对应OSI七层模型的传输层IP对应网络层这两层称为逻辑网络.而物理层和数据链路层称为物理层保持与OSI的规定一致

比如你能看得见摸得着的通过网络设备诸如网线，路由器，交换机等联系起来的pc网络就是物理网络。而这个网络中所使用的协议，或者网络结构，比如这个网络分多个子网或者多重层级关系，这些都是靠逻辑网络来划分的。

网络节点是指一台电脑或其他设备与一个有独立地址和具有传送或接收数据功能的网络相连。节点可以是工作站、客户、网络用户或个人计算机，还可以是服务器、打印机和其他网络连接的设备。每一个工作站﹑服务器、终端设备、网络设备，即拥有自己唯一网络地址的设备都是网络节点。整个网络就是由这许许多多的网络节点组成的，把许多的网络节点用通信线路连接起来，形成一定的几何关系，这就是计算机网络拓扑。

## 静态NAT

静态NAT，是建立内部本地地址和内部全局地址的一对一永久映射。当外部网络需要通过固定的全局可路由地址访问内部主机，静态NAT就显得十分重要。

### NAT使用地址

* A 类：10.0.0.0～10.255.255.255
* B 类：172.16.0.0～172.31.255.255
* C 类：192.168.0.0～192.168.255.255

## 报文交换和报文路由

报文交换（英文：message switching），又称存储转发交换，是数据交换的三种方式之一（电路交换、分组交换），报文整个地发送，一次一跳。报文交换是分组交换的前身，是由莱昂纳多·克莱洛克于1961年提出的。

报文交换的主要特点是：存储接收到的报文，判断其目标地址以选择路由，最后，在下一跳路由空闲时，将数据转发给下一跳路由。报文交换系统现今都由分组交换或电路交换网络所承载。

报文交换是以报文为数据交换的单位，报文携带有目标地址、源地址等信息，在交换结点采用存储转发的传输方式，因而有以下优缺点：

**优点**

1. 报文交换不需要为通信双方预先建立一条专用的通信线路，不存在连接建立时延，用户可随时发送报文。
2. 由于采用存储转发的传输方式，使之具有下列优点：a.在报文交换中便于设置代码检验和数据重发设施，加之交换结点还具有路径选择，就可以做到某条传输路径发生故障时，重新选择另一条路径传输数据，提高了传输的可靠性；b.在存储转发中容易实现代码转换和速率匹配，甚至收发双方可以不同时处于可用状态。这样就便于类型、规格和速度不同的计算机之间进行通信；c.提供多目标服务，即一个报文可以同时发送到多个目的地址，这在电路交换中是很难实现的；d.允许建立数据传输的优先级，使优先级高的报文优先转换。
3. 通信双方不是固定占有一条通信线路，而是在不同的时间一段一段地部分占有这条物理通路，因而大大提高了通信线路的利用率。

**缺点**

1. 由于数据进入交换结点后要经历存储、转发这一过程，从而引起转发时延（包括接收报文、检验正确性、排队、发送时间等），而且网络的通信量愈大，造成的时延就愈大，因此报文交换的实时性差，不适合传送实时或交互式业务的数据。
2. 报文交换只适用于数字信号。
3. 由于报文长度没有限制，而每个中间结点都要完整地接收传来的整个报文，当输出线路不空闲时，还可能要存储几个完整报文等待转发，要求网络中每个结点有较大的缓冲区。为了降低成本，减少结点的缓冲存储器的容量，有时要把等待转发的报文存在磁盘上，进一步增加了传送时延。

**报文路由**

从发送点至目的地之间用于传输报文的信号链路或串接的相邻链路。

## IPv4/IPv6隧道技术

### 手动隧道

即边界设备不能自动获得隧道终点的IPv4地址，需要手工配置隧道终点的IPv4地址，报文才能正确发送至隧道终点，通常用于路由器到路由器之间的隧道，常用的手动隧道技术有IPv6 over IPv4手动隧道和IPv6 over IPv4 GRE隧道。

![ipv4-ipv6-2](ipv4-ipv6-2.png)

上图为IPv6 over IPv4手动隧道封装格式，其转发机制为：当隧道边界设备的IPv6侧收到一个IPv6报文后， 根据IPv6报文的目的地址查找IPv6路由转发表，如果该报文是从此虚拟隧道接口转发出去，则根据隧道接口配置的隧道源端和目的端的IPv4地址进行封装。原IPv6报文变成一个IPv4报文，并交给IPv4协议栈处理。报文通过IPv4网络转发到隧道的终点。隧道终点收到一个隧道协议报文后，进行隧道解封装。解封装后的报文交给IPv6协议栈处理。采用手工配置隧道方式进行互通的节点间必须有可用的IPv4连接，并且至少要具有一个全球惟一的IPv4地址，每个节点都要支持IPv6，路由 器需要支持双协议栈，在隧道要经过NAT设施的情况下该机制失效。

使用标准的GRE隧道技术，在IPv4的GRE隧道上承载IPv6数据报文，提供点到点连接服务，两点之间都是一条单独的隧道。GRE隧道把IPv6作为乘客协议，将GRE作为承载协议，其本身并不限制被封装的协议和传输协议，一个GRE隧道中被封装的协议可以是协议中允许的任意协议(可以是IPv4、IPv6、OSI、MPLS等)。传输机制与IPv6 over IPv4手动隧道相同：

![gre](gre.png)

### 自动隧道

即边界设备可以自动获得隧道终点的IPv4地址，所以不需要手工配置终点的IPv4地址，一般的做法是隧道的两个接口的IPv6地址采用内嵌IPv4地址的特殊IPv6地址形式，这样路由设备可以从IPv6报文中的目的IPv6地址中提取出IPv4地址，自动隧道可用于主机到主机，或者主机到路由器之间，常用的自动隧道技术有IPv4兼容IPv6自动隧道、6to4隧道和ISATAP隧道。

IPv4兼容IPv6自动隧道，其承载的IPv6报文的目的地址(即自动隧道所使用的特殊地址)是IPv4兼容IPv6地址。IPv4兼容IPv6地址的前96位全部为0，后32位为IPv4地址。下图为IPv4兼容IPv6自动隧道转发机制图：

![ipv4-ipv6](ipv4-ipv6.png)

6to4隧道也是一种自动隧道，隧道也是使用内嵌在IPv6地址中的IPv4地址建立的，同时是一种特殊配置的中继路由，允许其能与原生IPv6网络进行通信。隧道可以使用在一台单独主机上，或一个本地网络上，但是采用6to4机制的节点必须至少具有一个全球惟一的IPv4地址，不利于仅支持IPv4的主机和仅支持IPv6的主机之间的互操作。下图为6to4中继示意图：

![6to4](6to4.png)

ISATAP隧道是另外一种自动隧道技术，同样使用了内嵌IPv4地址的特殊IPv6地址形式，和6to4不同的是，6to4是使用IPv4地址做为网络前缀，而ISATAP用IPv4地址做为接口标识，将IPv4网络为一个非广播多路访问网络的数据链路层，因此它不需要底层的IPv4网络基础设施来支持多播。下图为ISATAP隧道示例：

![isatap](isatap.png)

## 网络节点和网络site

**网络节点**

是指一台电脑或其他设备与一个有独立地址和具有传送或接收数据功能的网络相连。节点可以是工作站、客户、网络用户或个人计算机，还可以是服务器、打印机和其他网络连接的设备。每一个工作站﹑服务器、终端设备、网络设备，即拥有自己唯一网络地址的设备都是网络节点。整个网络就是由这许许多多的网络节点组成的，把许多的网络节点用通信线路连接起来，形成一定的几何关系，这就是计算机网络拓扑。

**网络site**

连续的逻辑子网覆盖的范围

## PA地址空间

PA地址空间（Provider-aggregatable space）指的即是提供商可聚合地址空间，是一段由区域互联网注册管理机构（Regional Internet Registry，RIR）分配给互联网服务提供商（ISP）的IP地址，这些IP地址可以被聚合为单一路由条目，从而降低路由表的规模，提高路由效率。与提供商无关地址空间不同，使用这种地址的用户在更换上游服务提供商的时候，无法继续使用原先的IP地址，因为这些地址是被分配给服务商的。

## 指定路由

即静态路由。静态路由（英语：Static routing）是一种路由的方式，路由项（routing entry）由手动配置，而非动态决定。与动态路由不同，静态路由是固定的，不会改变，即使网络状况已经改变或是重新被组态。一般来说，静态路由是由网络管理员逐项加入路由表。使用静态路由有多个原因，通常在没有到目的 IP 地址的动态路由或要重写动态学习路由时使用。

**优点**

使用静态路由的另一个好处是网络安全保密性高。动态路由因为需要路由器之间频繁地交换各自的路由表，而对路由表的分析可以揭示网络的拓扑结构和网络地址等信息。因此，网络出于安全方面的考虑也可以采用静态路由。不占用网络带宽，因为静态路由不会产生更新流量。静态路由适用于中小型网络。

**缺点**

大型和复杂的网络环境通常不宜采用静态路由。一方面，网络管理员难以全面地了解整个网络的拓扑结构；另一方面，当网络的拓扑结构和链路状态发生变化时，路由器中的静态路由信息需要大范围地调整，这一工作的难度和复杂程度非常高。当网络发生变化或网络发生故障时，不能重选路由，很可能使路由失败。

## 管理信息结构SMI

SMI 是简单网络管理协议（SNMP）的一部分，指定了在 SNMP 的 MIB 中用于定义管理目标的规则。

SMI 是一种语言，是为了确保网络管理数据的语法和语义明确和无二义性而定义的语言。它是定义被管理网络实体中特定数据的语言，同时它定义了数据类型、对象模型，以及写入和修改管理信息的规则。

## 路由器和交换机处理报文

**路由器收到二层报文，怎么处理？按收到二层报文是单播、组播、广播来分析**

* 若收到一个二层单播帧，对于路由器来讲，是一个三层设备，当然兼具二层的功能，所以当收到一个单播帧的时候，要判断这个帧的目的mac地址是不是接口的mac地址，如果是，解封装去看三层的ip地址，再看三层目的ip地址是不是接口的ip地址，如果是，交给接口处理，如果不是，去查找路由表，重新去做一个二层帧的封装，继续往下查找。如果目的mac不是接口的mac地址，直接丢掉。
* 若收到一个二层广播帧，那么是arp广播，它就会解封装，看arp信息里请求的ip地址是谁，如果说请求里的是路由器所在接口的IP地址，一定会去响应；如果说请求的IP地址不是路由器接口的IP地址，同时路由器没有开启ARP代理，一定会丢弃，如果ARP请求的不是路由器接口的，是后面的网段，并且开启了ARP代理，路由器去判断有没有去往目标网段的路由，如果有，就去做代理。
* 若收到一个二层组播帧，要看路由器的接口有没有加入这个组，缺省情况下，路由器接口加入了224.0.0.1、224.0.0.2（使能了组播功能就加入了），如果路由器接口没有加入到这个组播组，那么丢弃。

**三层交换机收到二层报文，怎么处理？按收到二层报文是单播、组播、广播来分析**

* 若收到一个二层单播帧，三层交换机需要配置一个vlan interface接口，配完后就会有一个IP地址，同时有一个IP地址所对应的mac地址，如果收到的目的mac地址是交换机的mac地址的话，先把二层帧解封装，把它送给三层处理，去查找路由表，如果不是交换机的mac地址，去看mac地址转发表，如果有，直接二层转发，不需要上送到三层，如果没有，未知单播泛洪。
* 若收到一个二层广播帧，比如ARP广播，那么这种情况下，会朝着所有接口去泛洪，除此之外，因为是三层交换机，会把ARP二层解封装，查看ARP里面的内容，看一下请求的ip地址是不是三层交换机vlan interface的IP地址，如果是就回复，如果不是就丢弃。
* 若收到一个二层组播帧，朝着所有端口泛洪，并且把组播帧解封装，送到vlan interface接口，看一下接口有没有加入到这个组，如果加入了要去响应或者处理，如果没有加入，不会响应也不会处理。

**路由器处理流程**

1. PC1已经知道PC2的IP地址（20.1.1.2），查看这个IP地址时，发现它和自己（10.1.1.2）不在同一个网段，会把报文转发给网关处理。
2. PC1已经配置好网关（10.1.1.1），所以就会尝试把报文发送给网关。但是PC1查看自己的ARP表项，发现是空的，默认情况下没有ARP表项。
3. PC1只有获取网关的MAC地址才能封装报文，所以它会发送ARP Request请求网关的MAC
4. 路由器收到这个ARP Request以后，发现Target IP是自己E0/1的IP地址，就会发送ARP Reply，把自己的MAC地址发送给PC1
5. PC1收到ARP Reply以后，就会创建一个ARP表项，以后发送给网关的MAC都会使用这个地址来填充；
6. PC1使用网关的MAC填充报文，然后发送给路由器
   1. 目的MAC填充的是aa:bb:cc:00:01:10，这是网关的MAC
   2. 目的IP是20.1.1.2，这个是PC2的IP地址
7. 路由器收到PC1发送的报文以后，会检查目的MAC地址，如果和自己的接口一样，就处理，否则丢弃；
8. 路由器会把报文的二层信息全部剥掉，只留下三层及以上的数据；
9. 路由器然后根据报文的目的IP地址，查找路由表，发现下一跳是出接口是E0/2；
10. 路由器就会使用出接口E0/2的MAC地址对之前的三层报文进行封装；
11. 封装完成的报文：源MAC是E0/2的MAC，目的IP地址不变，高层的ICMP内容也不变；
12. 目的MAC是PC2的MAC：路由器在发送报文给PC2之前，会发送ARP请求PC2的MAC
13. PC2会先检查目的MAC地址，是否和自己网卡MAC相同，如果不相同， 则丢弃报文；
14. 如果相同，则上送高层处理，然后回复ICMP，回复的ICMP的源MAC是PC2自己网卡的MAC；
15. 路由器对收到的PC2的报文的处理和PC1类似，也会重新封装二层MAC信息，然后转发给PC1；

## RD & RT

路由区分器（RD）将一个客户的路由（每个客户路由表有一个VRF）与另一个客户的路由分开。在一个VRF中，RD被预加到每个路由上（预加64位标识符），以识别该路由属于哪个VPN。在与其他PE路由器交换VPN路由时，RD与路由一起通过MP-BGP携带。

路由目标是一个64位的标识符，作为MP-BGP属性的一部分，用于识别哪个路由应该被输出或输入到特定的VPN。我们可以将路由目标应用于VRF，以控制路由的导入和导出。

在配置VRF lite的情况下，虽然RD是必须配置的，但RT配置可能不需要。此外，路由目标可以分为两种类型--出口路由目标和进口路由目标。

![rd-rt](rd-rt.jpg)

## RIB & FIB & MAC Table & ARP Table

### RIB

在计算机网络中，路由器的主要工作就是为经过路由器的每个数据包寻找一条最佳的传输路径，并将该数据有效地传送到目的站点。为了能够实现从众多路径中选择最佳的传输路径，路由器中保存了周边网络的拓扑信息和各种路径参数，我们将这张表称作路由表。

路由表（routing table）或称路由择域信息库（RIB, Routing Information Base），是一个存储在路由器或者联网计算机中的电子表格（文件）或类数据库。路由表存储着指向特定网络地址的路径（在有些情况下，还记录有路径的路由度量值）。路由表建立的主要目标是为了实现路由协议和静态路由选择。

在每一个路由器设备中，通常都维护了两张比较相似的表，分别为：

* 路由信息表（Routing Information Base），简称为RIB表、路由表
* 转发信息表（Forwarding Information Base）, 简称为FIB表、转发表

其中，路由表（RIB表）用来决策路由；转发表用来转发分组。

#### 路由表的下一跳

**在路由表中，每一项都包括如下内容**

* 目的网络地址(Destination) + 子网掩码(Genmask)：网络地址和网络掩码共同确定本机可以达到的目的网络范围，通常情况下，目的网络范围包含以下几种情况： (1) 主机地址：某个特定主机的网络地址； (2) 子网地址：某个特定子网的网络地址； (3)默认路由：所有未在路由表中指定的网络地址，用0.0.0.0统一匹配，用于配置默认网关(ubantu虚拟机中默认路由显示为default)
* 网关（Gateway）/下一跳（Next Hop）：一般终端设备如（PC，手机等）接入网络时，无需配置任何路由信息，而是通过路由器的DHCP协议分配IP地址，终端设备接收IP地址的同时会将本设备的网关设置为直连的路由器。而后上网过程中所有的报文在查询路由时，由于没有其他路由，因此被直接发送到了网关设备，有网关设备进行后续转发功能。而网络设备一般通过配置动态路由协议来更新路由表,除此之外也会设置默认网关。在收到数据包时如果路由表中有对应的路由表项，则通过此表项的出接口发送到下一跳网络设备，如果没有匹配到相应的路由表项，则需要发给默认网关，有网关进行后续转发处理工作。
* 接口（Iface）：接口定义了针对特定的网络目的地址，路由器用于转发数据包的出接口。即用来确定数据包从哪个网口上发送到下一跳设备。
* 跳数（Metric）：跳数用于指出路由的成本，通常情况下代表:到达目标地址所需要的总路由器个数，一个跳数代表经过一个路由器，IP数据报首部中的TTL字段就是该数据报所能存活的总跳数。跳数越少往往代表着该路由成本越低，跳数越多则说明成本越高。当具有多条达到相同目的网络的路由选项时，路由算法会选择具有更少跳数的路由。
* 标志（Flag）：路由表中常见的flag标记有
  * U：路由是动态的；
  * H：目标是一个主机；
  * G：路由指向网关；
  * R：恢复动态路由产生的表项；
  * D：由路由的后台程序动态安装；
  * M：由路由的后台程序修改；
  * !： 拒绝路由。
* 查询次数（Use）：此路由项被路由软件查找的次数。

**路由表中有三类路由**

* 直连路由（由链路层协议发现的路由）
* 静态路由（由管理员手动配置的路由）
* 动态路由（由动态路由协议发现的路由）

**静态路由表特点**

静态路由是由管理员在路由器中手动配置的固定路由，由管理员负责维护工作，静态路由不会超时老化、也不会同网络拓扑结构的变化发生变化。静态路由由于完全需要管理员的维护，不能实时感知网络拓扑并进行调整，通常只用于小规模、拓扑简单的网络中。

**动态路由表特点**

动态路由表由动态路由协议创建、更新、维护；常见的动态路由协议有：BGP协议、RIP协议、OSPF协议、ISIS协议、EIGRP协议等。动态路由协议最大的优势是：可以实时感知网络拓扑的变化，并对路由表做出相应的调整；网络扩展性好，适合大中型网络；

**路由表匹配原则**

* 精确匹配算法
* 最长前缀匹配算法(Longest Prefix Matching, 简称LPM)

#### 为什么遵循最长匹配优先

因为路由表的每个表项都指定了一个网络，所以一个目的地址可能与多个表项匹配，最明确的表项，即子网掩码最长的一个就叫最最长前缀匹配。之所以这样称呼他，是因为这个表项也是路由表中与目的地址的高位匹配得最多的表项。

例如考虑这两个IPv4的路由表：192.168.2.0/24和192.168.2.0/16

在要查找地址192.168.2.16时，这两个表项都匹配，也即是说都包含着要查找的地址。此时前缀最长的路由就是192.168.2.0/24，因为他的子网掩码比其他的表项要长，使得它更加明确。路由表中常常包含一个默认路由，这个路由在所有表项都不匹配时有着最短的前缀匹配。

**典型的匹配算法**

* 以Linux的路由查找算法为代表的的哈希(桶)算法
* Linux的LC-Trie树查找算法
* BSD/Cisco的Radix查找算法
* BSD/Cisco的256叉树查找算法
* DPDK中采用的分段查找算法(类似多级页表查询方式)

### FIB

路由器转发分组的关键是FIB表，在系统中报文转发时查找的是FIB表而非路由表。这是因为路由表表示所有的有效路由所形成的表项，并不指导转发。FIB表是网络层用来控制数据报发送的。FIB中包含了路由器在转发报文时所必需的一组最小信息。

当路由表中存在多个路由项可以匹配目的IP地址时，路由查找进程会选择其中掩码最长的路由项用于转发。那么路由表中路由项数量越多，所需查找及匹配的次数也就越多，其转发效率也就越低。为了做到控制平面和转发平面的分离，系统构建了另一张FIB表，也称为转发表，专注于数据报文的转发，其中FIB的表项来源于路由表项。

在计算路由信息的时候，不同路由协议所计算出来的路径可能会不同。在这种情况下，路由器会选择优先级较高的路由协议发现的路由作为最优路由，并置为Active状态；而其他路由作为备份路由，置为Inactive状态。此时Active状态的路由表项会由系统导入FIB表中，作为系统转发的依据。另外，在某些系统中，FIB表项也可能来源于ARP解析，即系统将通过ARP解析而得到的本地网段内的主机路由也添加到FIB表中。由于FIB表中没有处于Inactive状态的冗余路由，通常FIB表项数量小于路由表项，所以可以设计将FIB表项加载到硬件中，以大大加快数据转发速度。

FIB表记录的主要是记录路由信息，在FIB表获取到下一跳地址，然后去邻接表是查找下一跳地址对应的MAC，进行rewrite MAC地址，实现转发。这个过程其实很快的。也可以理解成FIB和ADJ表是同时运作。

**快速转发表**

第一个报文到达路由器的接口后，路由器查找快速转发表以期快速转发。但因为这个报文是第一个报文，快速转发表并没有这条数据流的转发信息的高速缓存，所以系统并不能进行快速转发。系统只能把这个报文转交到普通的FIB转发流程，由CPU负责在FIB表中查找相关转发项，然后进行封装，从出接口转发出去。与此同时，系统记录报文中的五元组信息，在高速缓存中生成相应快速转发信息。

### Mac表（Media Access Control Table）

从ISO网络模型上划分来说，路由表位于网络层，它用来进行路由和寻址功能。而Mac表则维护数据链路层，用来记录MAC地址到端口之间的映射。

**MAC表中包括的内容有**

* MAC地址
* 物理接口
* Mac条目类型（可能）
* 老化时间
* VLAN-ID（可能）

静态MAC地址与静态路由一样，有管理员负责管理维护；而动态Mac表项则是通过学习而来。在交换机中一般存在两个重要线程：地址学习线程、报文转发线程。

**地址学习线程**

* 源MAC学习法: 交换机从网络上收到报文后，利用数据包的源MAC地址进行学习，并建立MAC表项。
* 端口移动机制：交换机收到报文后，如果发现报文接收端口与MAC表中对应的端口不一致时，进行端口移动，将Mac地址重新学习到新的端口上。
* 地址老化机制：如果长时间没有收到某Mac表项对应的报文，则删除此表项。等下次报文来时重新进行学习。

**报文转发线程**

* 交换机收到报文后，根据报文中的目的Mac查询Mac表。如果找到，则从相应的端口发出；如果没有找到，则向除入端口以外的所有端口发送（即传说中的泛洪）；
* 如果交换机收到的报文目的Mac和源Mac所在端口相同，则丢弃此报文；
* 交换机收到的目的Mac为广播报文时，则向除入端口以外的所有端口转发广播报文。

### ARP表（Address Resolution Table）

在7层OSI模型中，IP地址工作在第三层(网络层)，Mac地址工作在第二层（数据链路层），两者之间各行其道，互不干扰。在进行报文转发时，目的IP地址我们是明确的，但是目的Mac地址却不知道；在封装报文时，先封装IP头部，然后填充二层头部。但是由于不知道Mac地址，因此二层头部无法填充，此时便需要用到ARP协议，它通过查询指定IP地址对应的Mac地址，构建出一个Mac表项，我们通过查询此表项便可以知道目的IP地址对应的Mac地址。因此在ARP表，本质上就是：IP地址和Mac地址间的映射。

**基本流程**

* 先查询路由表，确定目的地址是否可达，如果可达则确定出接口和下一跳信息
* 再查询ARP表，获取到目的地址对应的Mac地址信息，构建完整的以太网报文。
* 最后查询Mac表，是为了确定报文的发送接口，确定了出接口，内核会将报文发送到对应的网卡驱动上，网卡在合适的时间会将报文发送到下一跳设备上。

## 逆向路径转发RPF

逆向路径转发（英语：Reverse path forwarding，简称RPF）是为路由器传输多播数据包时确保一个无循环环境、以及在传输单播数据包时防止IP地址欺骗的一种技术。

**广播模式**

当一个广播分组到达一个路由器的时候，该路由器对他进行检查，看它到来的线路是否是通常用来给广播源发送分组的线路。 如果是，则有可能此分组是沿着最佳线路被转发过来，路由器将该分组转发到除到来的那条线路之外的所有其他线路。 否则，此分组被当作一个可能的重复分组被丢弃。 通常汇集树被用作来判断是否是最佳线路。

**多播RPF**

多播RPF，配合MSDP及PIM等多播路由协议以确保无循环地传递多播数据包。在多播路由中，用作决定转递数据包的是来源地址，而非像单播中使用目的地地址。

当一个多播数据包进入路由器接口，路由器会查看该接口可到达的网络的清单，意即：路由器检查数据包的逆向路径。如果路由器找到一个符合该来源地址的路由表条目，RPF检查通过，并且分组被转发到参与该多播组多播的所有其他接口。如果RPF检查失败，则该数据包被丢弃。因此，分组转发的结果基于分组的反向路径而不是前向路径。RPF路由器只会转递那些路由表中有与来源地址所相应条目的数据包，以确保不会产生任何循环。

这对有冗余连接的多播环境来说是致命性地必要。因为同一个多播数据包可以从不同的接口进入同一只路由器，RPF测试是决定该数据包继续转送与否时不可划缺的一部分。如果路由器发送所有来自接口A的多播数据包到接口B，而同时发送所有来自接口B的包封到接口A，两个接口都可能会收到同一个数据包，这将会产生很典形的路由循环因为数据包只会一直被传输下去直到其TTL字段到期。但即使考虑到TTL过期，任何类形的路由循环都理应尽可能地避免，因为这都会短暂地大幅减低网络的可用性。

**单播RPF（uRPF）**

* 严格模式：在严格模式下，每个传入数据包都根据FIB进行测试，如果“传入”接口不是最佳反向路径，则数据包检查失败。默认情况下，失败的数据包被丢弃。
* 可能模式：FIB维护到给定IP地址的备用路由。如果“传入”接口与任何与该IP地址相关联的路由匹配，则该分组被转发。否则，数据包被丢弃。
* 宽松模式：每个进入的单播数据包的来源地址同样会被检查。如果来源地址是无经由该接口的路径到达，检查将失败。

## 网络计费

Metering是计量计费，无需预留资源，根据用户需求进行调整，灵活性强

## 控制平面和数据平面

控制平面与转发平面可以是物理分离，也可以是逻辑分离。高端的网络设备(如核心交换机、核心路由器)一般采用物理分离。其主控板上的CPU不负责报文转发，专注于系统的控制；而业务板则专注于数据报文转发。如果主控板损坏，业务板仍然能够转发报文。

## 物理和逻辑网络

* 物理网络：使用网络的物理地址直接可达的范围，通常由物理线路进行连接
* 逻辑网络：一个逻辑网络地址前缀覆盖的范围，比如以一定格式开头的IP地址